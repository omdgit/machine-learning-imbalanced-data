{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassification cost as part of training\n",
    "\n",
    "There are 2 ways in which we can introduce cost into the learning function of the algorithm with Scikit-learn:\n",
    "\n",
    "- Defining the **class_weight** parameter for those estimators that allow it, when we set the estimator\n",
    "- Passing a **sample_weight** vector with the weights for every single observation, when we fit the estimator.\n",
    "\n",
    "\n",
    "With both the **class_weight** parameter or the **sample_weight** vector, we indicate that the loss function should be modified to accommodate the class imbalance and the cost attributed to each misclassification.\n",
    "\n",
    "## parameters\n",
    "\n",
    "**class_weight**: can take 'balanced' as argument, in which case it will use the balance ratio as weight. Alternatively, it can take a dictionary with {class: penalty}, pairs. In this case, it penalizes mistakes in samples of class[i] with class_weight[i].\n",
    "\n",
    "So if class_weight = {0:1, and 1:10}, misclassification of observations of class 1 are penalized 10 times more than misclassification of observations of class 0.\n",
    "\n",
    "**sample_weight** is a vector of the same length as y, containing the weight or penalty for each individual observation. In principle, it is more flexible, because it allows us to set weights to the observations and not to the class as a whole. So in this case, for example we could set up higher penalties for fraudulent applications that are more costly (money-wise)than to those fraudulent applications that are of little money.\n",
    "\n",
    "## Important\n",
    "\n",
    "If you use both class_weight and sample_weight, the final penalty will be **the combination of the 2**, so be very careful\n",
    "\n",
    "## Demo\n",
    "\n",
    "In this demo, I will introduce cost-sensitive learning to Logistic Regression. But keep in mind that you can do the same with almost every other classifier in Scikit-learn using **sample_weight** or, using **Class_weight** in those estimators that have that attribute.\n",
    "\n",
    "## Classifiers that support class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "ExtraTreeClassifier\n",
      "ExtraTreesClassifier\n",
      "HistGradientBoostingClassifier\n",
      "LinearSVC\n",
      "LogisticRegression\n",
      "LogisticRegressionCV\n",
      "NuSVC\n",
      "PassiveAggressiveClassifier\n",
      "Perceptron\n",
      "RandomForestClassifier\n",
      "RidgeClassifier\n",
      "RidgeClassifierCV\n",
      "SGDClassifier\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "# NOTE, THIS CELL WILL NOT WORK WITH SKLEARN VERSION > 0.24\n",
    "# JUST COMMENT IT OUT, OR DELETE THIS CELL TO CARRY ON WITH THE NOTEBOOK.\n",
    "\n",
    "# Let's find out which classifiers from sklearn support class_weight\n",
    "# as part of the __init__ method, that is, when we set the m up\n",
    "\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimators = all_estimators(type_filter='classifier')\n",
    "\n",
    "for name, class_ in estimators:\n",
    "    try:\n",
    "        if hasattr(class_(), 'class_weight'):\n",
    "            print(name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all classifiers support class_weight. For those which don't, like GradientBoostingClassifier, we can still use sample_weight when we fit the estimator.\n",
    "\n",
    "## Demo\n",
    "\n",
    "In this demo, we are going to introduce the misclassification cost in Logistic Regression, using class_weight and then sample_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics  # omd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>32.69</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1256.8</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1595.1</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>445.2</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>608.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>20.5</td>\n",
       "      <td>-52.5</td>\n",
       "      <td>...</td>\n",
       "      <td>762.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>27.27</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1623.6</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1491.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>658.2</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.91</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1921.6</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2047.7</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>554.2</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>464.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>479.5</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2     3     4       5     6     7     8     9  ...      65   \n",
       "0  52.0  32.69  0.30   2.5  20.0  1256.8 -0.89  0.33  11.0 -55.0  ...  1595.1  \\\n",
       "1  58.0  33.33  0.00  16.5   9.5   608.1  0.50  0.07  20.5 -52.5  ...   762.9   \n",
       "2  77.0  27.27 -0.91   6.0  58.5  1623.6 -1.40  0.02  -6.5 -48.0  ...  1491.8   \n",
       "3  41.0  27.91 -0.35   3.0  46.0  1921.6 -1.36 -0.47 -32.0 -51.5  ...  2047.7   \n",
       "4  50.0  28.00 -1.32  -9.0  12.0   464.8  0.88  0.19   8.0 -51.5  ...   479.5   \n",
       "\n",
       "     66    67   68    69     70    71    72    73  target  \n",
       "0 -1.64  2.83 -2.0 -50.0  445.2 -0.35  0.26  0.76      -1  \n",
       "1  0.29  0.82 -3.0 -35.0  140.3  1.16  0.39  0.73      -1  \n",
       "2  0.32 -1.29  0.0 -34.0  658.2 -0.76  0.26  0.24      -1  \n",
       "3 -0.98  1.53  0.0 -49.0  554.2 -0.83  0.39  0.73      -1  \n",
       "4  0.68 -0.59  2.0 -36.0   -6.9  2.02  0.14 -0.23      -1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# only a few observations to speed the computaton\n",
    "\n",
    "# data = pd.read_csv('../kdd2004.csv').sample(10000)\n",
    "data = pd.read_csv('../kdd2004.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "-1    0.991108\n",
       " 1    0.008892\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalanced target\n",
    "\n",
    "data.target.value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102025, 74), (43726, 74))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # drop the target\n",
    "    data['target'],  # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with class_weight\n",
    "\n",
    "# we initialize the cost / weights when we set up the transformer\n",
    "\n",
    "def run_Logit(X_train, X_test, y_train, y_test, class_weight):\n",
    "    \n",
    "    # weights introduced here\n",
    "    logit = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='newton-cg',\n",
    "        random_state=0,\n",
    "        max_iter=10,\n",
    "        n_jobs=4,\n",
    "        class_weight=class_weight # weights / cost\n",
    "    )\n",
    "    \n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print(\n",
    "        'Logistic Regression ROC AUC: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print(\n",
    "        'Logistic Regression ROC AUC: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "    preds = logit.predict(X_test)\n",
    "    print(f\"Logistic Regression Precision: {metrics.precision_score(y_test, preds)}\")\n",
    "    print(f\"Logistic Regression Recall: {metrics.recall_score(y_test, preds)}\")\n",
    "    print(f\"Logistic Regression F1: {metrics.f1_score(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "\n",
      "Train set\n",
      "Logistic Regression ROC AUC: 0.9230210002189093\n",
      "Test set\n",
      "Logistic Regression ROC AUC: 0.9256916712192443\n",
      "Logistic Regression Precision: 0.9823788546255506\n",
      "Logistic Regression Recall: 0.5506172839506173\n",
      "Logistic Regression F1: 0.7056962025316456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using imbalanced dataset\n",
    "\n",
    "run_Logit(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omd \n",
    "\n",
    "def performance(X, y, model, title=None):\n",
    "\n",
    "    # Predict probabilities on the test set\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    y_preds = model.predict(X)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = metrics.roc_auc_score(y, y_probs)\n",
    "    precision = metrics.precision_score(y, y_preds)\n",
    "    recall = metrics.recall_score(y, y_preds)\n",
    "    f1 = metrics.f1_score(y, y_preds)\n",
    "    aupr = metrics.average_precision_score(y, y_probs)\n",
    "\n",
    "    if title is None:\n",
    "        title = 'Performance metrics:'\n",
    "    else:\n",
    "        title = f'Performance metrics: {title}'\n",
    "    print(title)\n",
    "    print(\"ROC AUC:\".ljust(10) + f\"{roc_auc:.2%}\".rjust(8))\n",
    "    print(\"Precision:\".ljust(10) + f\"{precision:.2%}\".rjust(8))\n",
    "    print(\"Recall:\".ljust(10) + f\"{recall:.2%}\".rjust(8))\n",
    "    print(\"F1:\".ljust(10) + f\"{f1:.2%}\".rjust(8))\n",
    "    print(\"AUPRC:\".ljust(10) + f\"{aupr:.2%}\".rjust(8))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: In the following code, how is the X_test and y_test_mod used in the xgb.fit() method? \n",
    "\n",
    "In the `xgb.fit()` method, `X_test` and `y_test_mod` are used as part of the `eval_set` parameter. The `eval_set` is a list of pairs, where each pair is a set of examples that will be used for validation during training. In this case, two pairs are provided: the training set `(X_train, y_train_mod)` and the test set `(X_test, y_test_mod)`.\n",
    "\n",
    "The `eval_metric` parameter specifies the evaluation metric to be used on the validation set. Here, `f1_eval` is used, which likely refers to the F1 score, a common metric for binary classification problems.\n",
    "\n",
    "The `early_stopping_rounds` parameter is used to stop training when the performance on the validation set doesn't improve for a specified number of rounds. In this case, if the F1 score doesn't improve for 10 rounds, training will stop early.\n",
    "\n",
    "So, `X_test` and `y_test_mod` are used to monitor the model's performance on an unseen dataset during training, and to potentially stop training early if the model isn't improving. This can help prevent overfitting to the training data.  \n",
    "\n",
    "## Question: So is there data leakage for the model's performance on forecasting X_test?  \n",
    "\n",
    "No, there is no data leakage in this case. Data leakage would occur if information from the test set, `X_test`, was used during the training of the model. However, in this case, `X_test` and `y_test_mod` are only used for validation purposes during training, not for the actual training itself.\n",
    "\n",
    "The model is trained on `X_train` and `y_train_mod`, and then its performance is evaluated on `X_test` and `y_test_mod`. This is a common practice in machine learning to assess how well the model generalizes to unseen data.\n",
    "\n",
    "However, it's important to note that if you use the test set for tuning hyperparameters or making decisions about the model based on its performance on the test set, then it could lead to a form of data leakage known as \"test set overuse\". This is because you're using the test set to make decisions during the model development process, which should ideally only be done using the training and validation sets. The test set should ideally only be used once, at the very end of your modeling process, to evaluate final model performance. But in the provided code, there's no evidence of such misuse. So, there's no data leakage in this context.\n",
    "\n",
    "## Question: Would the following code be appropriate to calculate the class weight and sample weight?\n",
    "\n",
    "```python\n",
    "class_weights = len(y_train) / y_train.value_counts()\n",
    "sample_weights = np.array([class_weights[y] for y in y_train])\n",
    "```\n",
    "**Yes, the code you provided is appropriate** for calculating both the class weights and sample weights based on the distribution of classes in the training set. Let me break down what each line does:\n",
    "\n",
    "```python\n",
    "class_weights = len(y_train) / y_train.value_counts()\n",
    "```\n",
    "This line calculates the class weights. `y_train.value_counts()` returns the count of each unique class label in `y_train`, and `len(y_train)` is the total number of samples in the training set. By dividing the total number of samples by the count of each class, you're essentially calculating the inverse of the class frequencies. This will give higher weights to less frequent classes and lower weights to more frequent classes.\n",
    "\n",
    "```python\n",
    "sample_weights = np.array([class_weights[y] for y in y_train])\n",
    "```\n",
    "This line calculates the sample weights based on the class weights. For each sample label `y` in `y_train`, it retrieves the corresponding class weight from the `class_weights` dictionary and assigns it to the sample weight for that sample. This way, each sample is assigned a weight based on the class it belongs to.\n",
    "\n",
    "Overall, this approach is suitable for assigning weights to address class imbalance in the training set. Just make sure to use these weights appropriately when training your model, as shown in the previous examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio: 111.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.47240\tvalidation_0-f1_err:0.72264\tvalidation_1-logloss:0.47316\tvalidation_1-f1_err:0.72488\n",
      "[1]\tvalidation_0-logloss:0.34251\tvalidation_0-f1_err:0.57021\tvalidation_1-logloss:0.34442\tvalidation_1-f1_err:0.61077\n",
      "[2]\tvalidation_0-logloss:0.25595\tvalidation_0-f1_err:0.55065\tvalidation_1-logloss:0.25820\tvalidation_1-f1_err:0.58770\n",
      "[3]\tvalidation_0-logloss:0.19627\tvalidation_0-f1_err:0.44729\tvalidation_1-logloss:0.19929\tvalidation_1-f1_err:0.49718\n",
      "[4]\tvalidation_0-logloss:0.15439\tvalidation_0-f1_err:0.42736\tvalidation_1-logloss:0.15748\tvalidation_1-f1_err:0.48543\n",
      "[5]\tvalidation_0-logloss:0.12324\tvalidation_0-f1_err:0.40061\tvalidation_1-logloss:0.12694\tvalidation_1-f1_err:0.45509\n",
      "[6]\tvalidation_0-logloss:0.10104\tvalidation_0-f1_err:0.39145\tvalidation_1-logloss:0.10478\tvalidation_1-f1_err:0.44207\n",
      "[7]\tvalidation_0-logloss:0.08520\tvalidation_0-f1_err:0.39646\tvalidation_1-logloss:0.08914\tvalidation_1-f1_err:0.45249\n",
      "[8]\tvalidation_0-logloss:0.07317\tvalidation_0-f1_err:0.38849\tvalidation_1-logloss:0.07718\tvalidation_1-f1_err:0.44385\n",
      "[9]\tvalidation_0-logloss:0.06316\tvalidation_0-f1_err:0.38188\tvalidation_1-logloss:0.06743\tvalidation_1-f1_err:0.43079\n",
      "[10]\tvalidation_0-logloss:0.05569\tvalidation_0-f1_err:0.37667\tvalidation_1-logloss:0.06021\tvalidation_1-f1_err:0.42946\n",
      "[11]\tvalidation_0-logloss:0.04982\tvalidation_0-f1_err:0.36707\tvalidation_1-logloss:0.05446\tvalidation_1-f1_err:0.42184\n",
      "[12]\tvalidation_0-logloss:0.04285\tvalidation_0-f1_err:0.34195\tvalidation_1-logloss:0.04784\tvalidation_1-f1_err:0.40681\n",
      "[13]\tvalidation_0-logloss:0.03913\tvalidation_0-f1_err:0.32653\tvalidation_1-logloss:0.04426\tvalidation_1-f1_err:0.39304\n",
      "[14]\tvalidation_0-logloss:0.03591\tvalidation_0-f1_err:0.32269\tvalidation_1-logloss:0.04090\tvalidation_1-f1_err:0.39145\n",
      "[15]\tvalidation_0-logloss:0.03283\tvalidation_0-f1_err:0.31144\tvalidation_1-logloss:0.03782\tvalidation_1-f1_err:0.37349\n",
      "[16]\tvalidation_0-logloss:0.02943\tvalidation_0-f1_err:0.29258\tvalidation_1-logloss:0.03448\tvalidation_1-f1_err:0.35909\n",
      "[17]\tvalidation_0-logloss:0.02652\tvalidation_0-f1_err:0.27679\tvalidation_1-logloss:0.03175\tvalidation_1-f1_err:0.34650\n",
      "[18]\tvalidation_0-logloss:0.02456\tvalidation_0-f1_err:0.26637\tvalidation_1-logloss:0.02991\tvalidation_1-f1_err:0.34124\n",
      "[19]\tvalidation_0-logloss:0.02228\tvalidation_0-f1_err:0.25533\tvalidation_1-logloss:0.02773\tvalidation_1-f1_err:0.32962\n",
      "[20]\tvalidation_0-logloss:0.02085\tvalidation_0-f1_err:0.24235\tvalidation_1-logloss:0.02651\tvalidation_1-f1_err:0.32830\n",
      "[21]\tvalidation_0-logloss:0.01915\tvalidation_0-f1_err:0.22723\tvalidation_1-logloss:0.02507\tvalidation_1-f1_err:0.31744\n",
      "[22]\tvalidation_0-logloss:0.01728\tvalidation_0-f1_err:0.21429\tvalidation_1-logloss:0.02334\tvalidation_1-f1_err:0.31262\n",
      "[23]\tvalidation_0-logloss:0.01597\tvalidation_0-f1_err:0.19548\tvalidation_1-logloss:0.02205\tvalidation_1-f1_err:0.28955\n",
      "[24]\tvalidation_0-logloss:0.01423\tvalidation_0-f1_err:0.17309\tvalidation_1-logloss:0.02051\tvalidation_1-f1_err:0.27886\n",
      "[25]\tvalidation_0-logloss:0.01351\tvalidation_0-f1_err:0.16534\tvalidation_1-logloss:0.01990\tvalidation_1-f1_err:0.27515\n",
      "[26]\tvalidation_0-logloss:0.01244\tvalidation_0-f1_err:0.15021\tvalidation_1-logloss:0.01895\tvalidation_1-f1_err:0.26327\n",
      "[27]\tvalidation_0-logloss:0.01144\tvalidation_0-f1_err:0.13495\tvalidation_1-logloss:0.01808\tvalidation_1-f1_err:0.24921\n",
      "[28]\tvalidation_0-logloss:0.00972\tvalidation_0-f1_err:0.10989\tvalidation_1-logloss:0.01639\tvalidation_1-f1_err:0.23010\n",
      "[29]\tvalidation_0-logloss:0.00888\tvalidation_0-f1_err:0.10000\tvalidation_1-logloss:0.01566\tvalidation_1-f1_err:0.22173\n",
      "[30]\tvalidation_0-logloss:0.00807\tvalidation_0-f1_err:0.09451\tvalidation_1-logloss:0.01501\tvalidation_1-f1_err:0.21826\n",
      "[31]\tvalidation_0-logloss:0.00758\tvalidation_0-f1_err:0.08989\tvalidation_1-logloss:0.01474\tvalidation_1-f1_err:0.21348\n",
      "[32]\tvalidation_0-logloss:0.00683\tvalidation_0-f1_err:0.07477\tvalidation_1-logloss:0.01408\tvalidation_1-f1_err:0.20678\n",
      "[33]\tvalidation_0-logloss:0.00617\tvalidation_0-f1_err:0.07236\tvalidation_1-logloss:0.01332\tvalidation_1-f1_err:0.20183\n",
      "[34]\tvalidation_0-logloss:0.00587\tvalidation_0-f1_err:0.06897\tvalidation_1-logloss:0.01312\tvalidation_1-f1_err:0.19678\n",
      "[35]\tvalidation_0-logloss:0.00546\tvalidation_0-f1_err:0.06358\tvalidation_1-logloss:0.01278\tvalidation_1-f1_err:0.19585\n",
      "[36]\tvalidation_0-logloss:0.00505\tvalidation_0-f1_err:0.05664\tvalidation_1-logloss:0.01255\tvalidation_1-f1_err:0.19213\n",
      "[37]\tvalidation_0-logloss:0.00463\tvalidation_0-f1_err:0.05364\tvalidation_1-logloss:0.01218\tvalidation_1-f1_err:0.18787\n",
      "[38]\tvalidation_0-logloss:0.00424\tvalidation_0-f1_err:0.04859\tvalidation_1-logloss:0.01175\tvalidation_1-f1_err:0.17633\n",
      "[39]\tvalidation_0-logloss:0.00388\tvalidation_0-f1_err:0.04245\tvalidation_1-logloss:0.01145\tvalidation_1-f1_err:0.17225\n",
      "[40]\tvalidation_0-logloss:0.00360\tvalidation_0-f1_err:0.03935\tvalidation_1-logloss:0.01131\tvalidation_1-f1_err:0.17717\n",
      "[41]\tvalidation_0-logloss:0.00329\tvalidation_0-f1_err:0.02994\tvalidation_1-logloss:0.01106\tvalidation_1-f1_err:0.17422\n",
      "[42]\tvalidation_0-logloss:0.00308\tvalidation_0-f1_err:0.02516\tvalidation_1-logloss:0.01089\tvalidation_1-f1_err:0.17126\n",
      "[43]\tvalidation_0-logloss:0.00293\tvalidation_0-f1_err:0.02463\tvalidation_1-logloss:0.01090\tvalidation_1-f1_err:0.17085\n",
      "[44]\tvalidation_0-logloss:0.00276\tvalidation_0-f1_err:0.02195\tvalidation_1-logloss:0.01077\tvalidation_1-f1_err:0.16223\n",
      "[45]\tvalidation_0-logloss:0.00258\tvalidation_0-f1_err:0.02142\tvalidation_1-logloss:0.01063\tvalidation_1-f1_err:0.15815\n",
      "[46]\tvalidation_0-logloss:0.00243\tvalidation_0-f1_err:0.01601\tvalidation_1-logloss:0.01058\tvalidation_1-f1_err:0.16484\n",
      "[47]\tvalidation_0-logloss:0.00218\tvalidation_0-f1_err:0.01329\tvalidation_1-logloss:0.01050\tvalidation_1-f1_err:0.16216\n",
      "[48]\tvalidation_0-logloss:0.00205\tvalidation_0-f1_err:0.00945\tvalidation_1-logloss:0.01046\tvalidation_1-f1_err:0.16176\n",
      "[49]\tvalidation_0-logloss:0.00185\tvalidation_0-f1_err:0.00945\tvalidation_1-logloss:0.01030\tvalidation_1-f1_err:0.16113\n",
      "[50]\tvalidation_0-logloss:0.00170\tvalidation_0-f1_err:0.00613\tvalidation_1-logloss:0.01012\tvalidation_1-f1_err:0.15737\n",
      "[51]\tvalidation_0-logloss:0.00162\tvalidation_0-f1_err:0.00613\tvalidation_1-logloss:0.01004\tvalidation_1-f1_err:0.15776\n",
      "[52]\tvalidation_0-logloss:0.00150\tvalidation_0-f1_err:0.00502\tvalidation_1-logloss:0.01000\tvalidation_1-f1_err:0.15672\n",
      "[53]\tvalidation_0-logloss:0.00143\tvalidation_0-f1_err:0.00502\tvalidation_1-logloss:0.01000\tvalidation_1-f1_err:0.15605\n",
      "[54]\tvalidation_0-logloss:0.00131\tvalidation_0-f1_err:0.00336\tvalidation_1-logloss:0.00996\tvalidation_1-f1_err:0.15500\n",
      "[55]\tvalidation_0-logloss:0.00125\tvalidation_0-f1_err:0.00280\tvalidation_1-logloss:0.00996\tvalidation_1-f1_err:0.15500\n",
      "[56]\tvalidation_0-logloss:0.00115\tvalidation_0-f1_err:0.00224\tvalidation_1-logloss:0.00983\tvalidation_1-f1_err:0.15433\n",
      "[57]\tvalidation_0-logloss:0.00110\tvalidation_0-f1_err:0.00224\tvalidation_1-logloss:0.00986\tvalidation_1-f1_err:0.15645\n",
      "[58]\tvalidation_0-logloss:0.00104\tvalidation_0-f1_err:0.00168\tvalidation_1-logloss:0.00989\tvalidation_1-f1_err:0.15657\n",
      "[59]\tvalidation_0-logloss:0.00094\tvalidation_0-f1_err:0.00168\tvalidation_1-logloss:0.00981\tvalidation_1-f1_err:0.14975\n",
      "[60]\tvalidation_0-logloss:0.00088\tvalidation_0-f1_err:0.00168\tvalidation_1-logloss:0.00983\tvalidation_1-f1_err:0.14687\n",
      "[61]\tvalidation_0-logloss:0.00079\tvalidation_0-f1_err:0.00056\tvalidation_1-logloss:0.00988\tvalidation_1-f1_err:0.14867\n",
      "[62]\tvalidation_0-logloss:0.00072\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00984\tvalidation_1-f1_err:0.14613\n",
      "[63]\tvalidation_0-logloss:0.00067\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00982\tvalidation_1-f1_err:0.14359\n",
      "[64]\tvalidation_0-logloss:0.00063\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00982\tvalidation_1-f1_err:0.14028\n",
      "[65]\tvalidation_0-logloss:0.00058\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00983\tvalidation_1-f1_err:0.14469\n",
      "[66]\tvalidation_0-logloss:0.00056\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00988\tvalidation_1-f1_err:0.13956\n",
      "[67]\tvalidation_0-logloss:0.00054\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00993\tvalidation_1-f1_err:0.13846\n",
      "[68]\tvalidation_0-logloss:0.00050\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00991\tvalidation_1-f1_err:0.13846\n",
      "[69]\tvalidation_0-logloss:0.00048\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00991\tvalidation_1-f1_err:0.13736\n",
      "[70]\tvalidation_0-logloss:0.00046\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00993\tvalidation_1-f1_err:0.13956\n",
      "[71]\tvalidation_0-logloss:0.00042\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00992\tvalidation_1-f1_err:0.13882\n",
      "[72]\tvalidation_0-logloss:0.00041\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00994\tvalidation_1-f1_err:0.13660\n",
      "[73]\tvalidation_0-logloss:0.00038\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00996\tvalidation_1-f1_err:0.13548\n",
      "[74]\tvalidation_0-logloss:0.00036\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00996\tvalidation_1-f1_err:0.13583\n",
      "[75]\tvalidation_0-logloss:0.00034\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00996\tvalidation_1-f1_err:0.13548\n",
      "[76]\tvalidation_0-logloss:0.00032\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.00997\tvalidation_1-f1_err:0.13437\n",
      "[77]\tvalidation_0-logloss:0.00031\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01001\tvalidation_1-f1_err:0.13212\n",
      "[78]\tvalidation_0-logloss:0.00030\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01001\tvalidation_1-f1_err:0.13212\n",
      "[79]\tvalidation_0-logloss:0.00029\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01002\tvalidation_1-f1_err:0.13290\n",
      "[80]\tvalidation_0-logloss:0.00028\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01004\tvalidation_1-f1_err:0.12953\n",
      "[81]\tvalidation_0-logloss:0.00027\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01008\tvalidation_1-f1_err:0.13178\n",
      "[82]\tvalidation_0-logloss:0.00026\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01010\tvalidation_1-f1_err:0.13178\n",
      "[83]\tvalidation_0-logloss:0.00025\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01013\tvalidation_1-f1_err:0.13437\n",
      "[84]\tvalidation_0-logloss:0.00023\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01018\tvalidation_1-f1_err:0.12840\n",
      "[85]\tvalidation_0-logloss:0.00022\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01019\tvalidation_1-f1_err:0.12840\n",
      "[86]\tvalidation_0-logloss:0.00022\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01023\tvalidation_1-f1_err:0.12581\n",
      "[87]\tvalidation_0-logloss:0.00021\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01026\tvalidation_1-f1_err:0.12581\n",
      "[88]\tvalidation_0-logloss:0.00020\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01026\tvalidation_1-f1_err:0.12467\n",
      "[89]\tvalidation_0-logloss:0.00019\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01031\tvalidation_1-f1_err:0.12727\n",
      "[90]\tvalidation_0-logloss:0.00019\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01034\tvalidation_1-f1_err:0.12581\n",
      "[91]\tvalidation_0-logloss:0.00018\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01036\tvalidation_1-f1_err:0.12581\n",
      "[92]\tvalidation_0-logloss:0.00018\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01035\tvalidation_1-f1_err:0.12760\n",
      "[93]\tvalidation_0-logloss:0.00017\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01032\tvalidation_1-f1_err:0.12647\n",
      "[94]\tvalidation_0-logloss:0.00017\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01034\tvalidation_1-f1_err:0.12647\n",
      "[95]\tvalidation_0-logloss:0.00016\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01037\tvalidation_1-f1_err:0.12614\n",
      "[96]\tvalidation_0-logloss:0.00016\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01040\tvalidation_1-f1_err:0.12647\n",
      "[97]\tvalidation_0-logloss:0.00016\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01042\tvalidation_1-f1_err:0.12907\n",
      "[98]\tvalidation_0-logloss:0.00015\tvalidation_0-f1_err:0.00000\tvalidation_1-logloss:0.01042\tvalidation_1-f1_err:0.12907\n",
      "ROC AUC for X_train: 100.00%\n",
      "Performance metrics: X_test\n",
      "ROC AUC:    99.29%\n",
      "Precision:  92.33%\n",
      "Recall:     83.21%\n",
      "F1:         87.53%\n",
      "AUPRC:      90.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# omd \n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "imbal_ratio = class_weight[-1] // class_weight[1]\n",
    "print(f\"Imbalance ratio: {imbal_ratio}\")\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = 1 - f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_err', err\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 12,\n",
    "    'scale_pos_weight': imbal_ratio,\n",
    "    # 'max_delta_step': 10,\n",
    "    'reg_alpha':0.5,\n",
    "    'reg_lambda':0.5,\n",
    "    # 'subsample': 0.9,\n",
    "    # 'colsample_bytree': 0.5\n",
    "}\n",
    "\n",
    "# xgb = XGBClassifier(**params, n_jobs=-1, random_state=0)\n",
    "xgb = XGBClassifier(n_jobs=-1, random_state=0)\n",
    "# xgb = XGBRFClassifier(**params, n_jobs=-1, random_state=0)\n",
    "\n",
    "y_train_mod = y_train.replace(-1, 0)\n",
    "y_test_mod = y_test.replace(-1, 0)\n",
    "\n",
    "# Calculate class_weights and sample_weights based on the class_weights\n",
    "class_weights = len(y_train) / y_train_mod.value_counts()\n",
    "sample_weights = np.array([class_weights[y] for y in y_train_mod])\n",
    "\n",
    "xgb.fit(X_train, y_train_mod, sample_weight=sample_weights, \n",
    "        eval_set=[(X_train, y_train_mod), (X_test, y_test_mod)], eval_metric=f1_eval, \n",
    "        early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# Calculate performance metrics\n",
    "roc_auc_train = roc_auc_score(y_train_mod, xgb.predict_proba(X_train)[:,1])\n",
    "print(f'ROC AUC for X_train: {roc_auc_train:.2%}')\n",
    "\n",
    "# Show model performance for X_test \n",
    "performance(X_test, y_test_mod, xgb, title=\"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omd\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "xgb.save_model('xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_test\n",
      "ROC AUC:    99.29%\n",
      "Precision:  92.33%\n",
      "Recall:     83.21%\n",
      "F1:         87.53%\n",
      "AUPRC:      90.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# omd\n",
    "\n",
    "# Create a new XGBoost model\n",
    "xgb_loaded = XGBClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "# Load the model from the file\n",
    "xgb_loaded.load_model('xgb_model.json')\n",
    "\n",
    "# Show model performance for X_test \n",
    "performance(X_test, y_test_mod, xgb_loaded, title=\"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120222</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38087</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58290</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79865</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45816</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  sample_weight\n",
       "120222  0        1.00881\n",
       "38087   0        1.00881\n",
       "58290   0        1.00881\n",
       "79865   0        1.00881\n",
       "45816   0        1.00881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111303</th>\n",
       "      <td>1</td>\n",
       "      <td>114.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43826</th>\n",
       "      <td>1</td>\n",
       "      <td>114.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94241</th>\n",
       "      <td>1</td>\n",
       "      <td>114.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43003</th>\n",
       "      <td>1</td>\n",
       "      <td>114.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142377</th>\n",
       "      <td>1</td>\n",
       "      <td>114.506173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  sample_weight\n",
       "111303  1     114.506173\n",
       "43826   1     114.506173\n",
       "94241   1     114.506173\n",
       "43003   1     114.506173\n",
       "142377  1     114.506173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame({'y': y_train_mod, 'sample_weight': sample_weights})\n",
    "display(df_temp[df_temp['y']==0].head())\n",
    "display(df_temp[df_temp['y']==1].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43721</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43722</th>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43723</th>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43724</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43725</th>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0      0.999979  0.000021\n",
       "1      0.999999  0.000001\n",
       "2      0.000000  1.000000\n",
       "3      0.999989  0.000011\n",
       "4      0.999988  0.000012\n",
       "...         ...       ...\n",
       "43721  0.999999  0.000001\n",
       "43722  0.999961  0.000039\n",
       "43723  0.999946  0.000054\n",
       "43724  0.999998  0.000001\n",
       "43725  0.999994  0.000007\n",
       "\n",
       "[43726 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = pd.DataFrame(pred_proba).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "pred_proba = xgb_loaded.predict_proba(X_test)[:]\n",
    "pred_proba = pd.DataFrame(pred_proba).round(6)\n",
    "# plt.hist(pred_proba[0], bins=10, ec='white', label='Negative')\n",
    "plt.hist(pred_proba[1], bins=10, ec='white', label='Positive')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> omd </font>\n",
    "## Calibrating the output probabilities of an XGBoost model can be achieved through a few methods:\n",
    "\n",
    "1. **Isotonic Regression**: This is a non-parametric method that can be used to transform the output probabilities to be more calibrated¹. Here's an example of how you might use it in Python:\n",
    "\n",
    "```python\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Assume y_pred_train are your predicted probabilities from the training set\n",
    "calibr = IsotonicRegression()\n",
    "calibr.fit(y_pred_train, y_train)\n",
    "\n",
    "# Now you can calibrate your test set predictions\n",
    "y_pred_test_calibrated = calibr.predict(y_pred_test)\n",
    "```\n",
    "\n",
    "2. **Platt Scaling**: This method involves fitting a logistic regression model to the model's scores. This can be done using `CalibratedClassifierCV` in scikit-learn with `method='sigmoid'`². However, this method may not work well with unbalanced problems or non-linear relationships².\n",
    "\n",
    "3. **Adjusting the `scale_pos_weight` parameter**: If you're dealing with imbalanced classes, the `scale_pos_weight` parameter in XGBoost can affect the calibration of your probabilities. You might want to experiment with different values for this parameter¹.\n",
    "\n",
    "4. **Tuning other hyperparameters**: Other hyperparameters such as `max_depth`, `lambda`, and `subsample` can also affect the calibration of your probabilities⁴. You might want to experiment with these as well.\n",
    "\n",
    "Remember, the best method for calibration can depend on your specific use case and data. It's often a good idea to try different methods and see which one works best for your situation. Also, always validate the calibration of your model using a separate validation set to avoid overfitting.\n",
    "\n",
    "Source: Conversation with Bing, 3/24/2024\n",
    "(1) Calibration curve of XGBoost for binary classification. https://stats.stackexchange.com/questions/417806/calibration-curve-of-xgboost-for-binary-classification.\n",
    "(2) XGBoost: how to adjust the probabilities of a binary classifier to .... https://datascience.stackexchange.com/questions/67342/xgboost-how-to-adjust-the-probabilities-of-a-binary-classifier-to-match-trainin.\n",
    "(3) XGBoost Classifier not capturing extreme probabilities. https://stats.stackexchange.com/questions/566392/xgboost-classifier-not-capturing-extreme-probabilities.\n",
    "(4) classification - How to calibrate an XGBoost classifier which has been .... https://stats.stackexchange.com/questions/565244/how-to-calibrate-an-xgboost-classifier-which-has-been-trained-on-a-sampled-datas.\n",
    "(5) XGBoost produce prediction result and probability. https://stackoverflow.com/questions/61082381/xgboost-produce-prediction-result-and-probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omd\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Calibrate the XGBClassifier\n",
    "calibrated = CalibratedClassifierCV(xgb_loaded, method='isotonic', cv=5)\n",
    "calibrated.fit(X_train, y_train_mod, sample_weight=sample_weights)\n",
    "\n",
    "# Now you can predict probabilities on the test set\n",
    "probabilities = calibrated.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# omd\n",
    "from matplotlib import ticker as mticker \n",
    "\n",
    "plt.hist(probabilities[:,1], bins=40, ec='white')\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "plt.gca().xaxis.set_major_formatter(mticker.StrMethodFormatter('{x:.0%}'))\n",
    "plt.title('Calibrated Probability Distribution')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.xlabel('Probability - Positive Class')\n",
    "plt.grid(True, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have trained an XGBoost classifier using sample weights to address class imbalance and you want to calibrate the predicted probabilities, you can use various calibration methods, such as Platt scaling or isotonic regression. These methods adjust the predicted probabilities to better reflect the true probability estimates.\n",
    "\n",
    "Here's how you can perform Platt scaling using scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming you have already trained an XGBoost classifier\n",
    "# and have X_train, y_train, X_test, y_test\n",
    "\n",
    "# Create a CalibratedClassifierCV instance\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=xgb.XGBClassifier(objective='binary:logistic'), method='sigmoid')\n",
    "\n",
    "# Fit the calibrated classifier on the training data\n",
    "calibrated_clf.fit(X_train, y_train, sample_weight=sample_weights)  # Assuming sample_weights are calculated\n",
    "\n",
    "# Predict probabilities for the training data\n",
    "calibrated_probs = calibrated_clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Now calibrated_probs contains the calibrated probabilities\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "1. We import `CalibratedClassifierCV` from scikit-learn.\n",
    "2. We create an instance of `CalibratedClassifierCV` with the XGBoost classifier (`xgb.XGBClassifier`) as the base estimator and set the calibration method to `'sigmoid'`, which corresponds to Platt scaling.\n",
    "3. We fit the calibrated classifier on the training data, including the sample weights if necessary.\n",
    "4. We use the calibrated classifier to predict probabilities for the training data. The calibrated probabilities are stored in `calibrated_probs`.\n",
    "\n",
    "After calibrating the probabilities, you can use them for further analysis or decision-making. Adjust the calibration method and parameters as needed for your specific problem and requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">omd</font>\n",
    "\n",
    "Calibrating the output of an XGBClassifier is not always necessary. The XGBoost algorithm, when used with the 'binary:logistic' objective function, should theoretically produce well-calibrated probabilities¹. However, there are certain situations where calibration might be beneficial or detrimental:\n",
    "\n",
    "1. **Imbalanced Classes**: If you're dealing with imbalanced classes, the `scale_pos_weight` parameter in XGBoost can affect the calibration of your model. Setting `scale_pos_weight` to a value other than 1 might skew your probabilities higher than the data would suggest¹.\n",
    "\n",
    "2. **Calibration Method**: The method used for calibration can also impact the results. For instance, using Platt scaling (method='sigmoid') with gradient boosting might not be the best choice, as gradient boosting tends to push probability toward 0 and 1¹. An alternative could be to try method='isotonic'¹.\n",
    "\n",
    "3. **Model Performance**: Calibration can sometimes negatively impact the performance of your model. For example, one user reported that after calibrating their XGBClassifier, the outputted probabilities were clipped at ~0.75¹.\n",
    "\n",
    "In conclusion, whether or not to calibrate your XGBClassifier depends on your specific use case and the characteristics of your data. It's recommended to experiment with different settings and evaluate the performance of your model accordingly. Always remember to validate your model using a separate test set or cross-validation to ensure its generalizability.\n",
    "\n",
    "Source: Conversation with Bing, 3/30/2024\n",
    "(1) Calibration curve of XGBoost for binary classification. https://stats.stackexchange.com/questions/417806/calibration-curve-of-xgboost-for-binary-classification.\n",
    "(2) How to Configure XGBoost for Imbalanced Classification. https://machinelearningmastery.com/xgboost-for-imbalanced-classification/.\n",
    "(3) How to use CalibratedClassifierCV on already trained xgboost model?. https://stackoverflow.com/questions/61508945/how-to-use-calibratedclassifiercv-on-already-trained-xgboost-model.\n",
    "(4) scikit learn - TypeError with Sklear XGBoost and Sklearn Calibrated .... https://stackoverflow.com/questions/66333573/typeerror-with-sklear-xgboost-and-sklearn-calibrated-classifier-cv.\n",
    "(5) Multiclass classification with xgboost classifier? - Stack Overflow. https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression ROC AUC: 0.9729997074477335\n",
      "Test set\n",
      "Logistic Regression ROC AUC: 0.972824915125416\n",
      "Logistic Regression Precision: 0.1343054489639294\n",
      "Logistic Regression Recall: 0.8641975308641975\n",
      "Logistic Regression F1: 0.23248090335436733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# cost estimated as imbalance ratio\n",
    "\n",
    "# 'balanced' indicates that we want same amount of \n",
    "# each observation, thus, imbalance ratio\n",
    "\n",
    "run_Logit(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.9458206883093916\n",
      "Test set\n",
      "Random Forests roc-auc: 0.9403544609384975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# cost estimated as imbalance ratio\n",
    "\n",
    "# alternatively, we can pass a different cost\n",
    "# in a dictionary, if we know it already\n",
    "\n",
    "run_Logit(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight={-1:1, 1:10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the cost and see what you get in terms of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression + sample_weight\n",
    "\n",
    "# we pass the weights / cost, when we train the algorithm\n",
    "\n",
    "def run_Logit(X_train, X_test, y_train, y_test, sample_weight):\n",
    "    \n",
    "    logit = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='newton-cg',\n",
    "        random_state=0,\n",
    "        max_iter=10,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    \n",
    "    # costs are passed here\n",
    "    logit.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print(\n",
    "        'Logistic Regression ROC AUC: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print(\n",
    "        'Logistic Regression ROC AUC: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "    preds = logit.predict(X_test)\n",
    "    print(f\"Logistic Regression Precision: {metrics.precision_score(y_test, preds)}\")\n",
    "    print(f\"Logistic Regression Recall: {metrics.recall_score(y_test, preds)}\")\n",
    "    print(f\"Logistic Regression F1: {metrics.f1_score(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_Logit() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# evaluate performance of algorithm built\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# using imbalanced dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_Logit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_Logit() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using imbalanced dataset\n",
    "\n",
    "run_Logit(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression ROC AUC: 0.9752730522962757\n",
      "Test set\n",
      "Logistic Regression ROC AUC: 0.9753286476692368\n",
      "Logistic Regression Precision: 0.13278627377844088\n",
      "Logistic Regression Recall: 0.8790123456790123\n",
      "Logistic Regression F1: 0.23071937783538563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/ml2023/lib/python3.8/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# cost estimated as imbalance ratio\n",
    "\n",
    "# with numpy.where, we introduce a cost of 99 to\n",
    "# each observation of the minority class, and 1\n",
    "# otherwise.\n",
    "\n",
    "run_Logit(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          sample_weight=np.where(y_train==1,99,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Cost-sensitive learning has improved the performance of the model.\n",
    "\n",
    "**HOMEWORK**\n",
    "\n",
    "Try other machine learning algorithms and other datasets available in imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
