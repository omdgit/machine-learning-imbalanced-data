{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Fraud Dataset  \n",
    "source: [www.kaggle.com/datasets/fraud.csv](https://www.kaggle.com/datasets/vardhansiramdasu/fraudulent-transactions-prediction/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "|**step**| maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).| \n",
    "|**type**| CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.| \n",
    "|**amount**| amount of the transaction in local currency.| \n",
    "|**nameOrig**| customer who started the transaction| \n",
    "|**oldbalanceOrg**| initial balance before the transaction| \n",
    "|**newbalanceOrig**| new balance after the transaction| \n",
    "|**nameDest**| customer who is the recipient of the transaction| \n",
    "|**oldbalanceDest**| initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).| \n",
    "|**newbalanceDest**| new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).| \n",
    "|**isFraud**| This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.|  \n",
    "|**isFlaggedFraud**| The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, ticker as mticker\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "from feature_engine import encoding as ce\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "import optuna\n",
    "from optuna.storages import RDBStorage\n",
    "# from optuna_dashboard import wsgi\n",
    "\n",
    "storage = RDBStorage(\"sqlite:///db.sqlite3\")\n",
    "# application = wsgi(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   step            int64  \n",
      " 1   type            object \n",
      " 2   amount          float64\n",
      " 3   nameOrig        object \n",
      " 4   oldbalanceOrg   float64\n",
      " 5   newbalanceOrig  float64\n",
      " 6   nameDest        object \n",
      " 7   oldbalanceDest  float64\n",
      " 8   newbalanceDest  float64\n",
      " 9   isFraud         int64  \n",
      " 10  isFlaggedFraud  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6354407\n",
      "1       8213\n",
      "Name: isFraud, dtype: int64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Imbalance of target \n",
    "print(df['isFraud'].value_counts(dropna=False))\n",
    "print(df['isFraud'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "nameOrig          0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "nameDest          0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "CASH_IN     1399284\n",
       "CASH_OUT    2237500\n",
       "DEBIT         41432\n",
       "PAYMENT     2151495\n",
       "TRANSFER     532909\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type')['type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nameOrig_tf\n",
       "C1    3290968\n",
       "C2     766936\n",
       "C3     327938\n",
       "C4     329176\n",
       "C5     330009\n",
       "C6     329312\n",
       "C7     330560\n",
       "C8     328926\n",
       "C9     328795\n",
       "Name: nameOrig_tf, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nameOrig_tf'] = [i[0:2] for i in df['nameOrig']]\n",
    "df.groupby('nameOrig_tf')['nameOrig_tf'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nameDest_tf\n",
       "C1    2177198\n",
       "C2     509697\n",
       "C3     216675\n",
       "C4     216903\n",
       "C5     216484\n",
       "C6     216051\n",
       "C7     221434\n",
       "C8     218371\n",
       "C9     218312\n",
       "M1    1113250\n",
       "M2     258735\n",
       "M3     111298\n",
       "M4     111116\n",
       "M5     111343\n",
       "M6     110943\n",
       "M7     111760\n",
       "M8     111350\n",
       "M9     111700\n",
       "Name: nameDest_tf, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nameDest_tf'] = [i[0:2] for i in df['nameDest']]\n",
    "df.groupby('nameDest_tf')['nameDest_tf'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5090096, 9), (1272524, 9), (5090096,), (1272524,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['isFraud', 'isFlaggedFraud'], axis=1),\n",
    "                                                    df['isFraud'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=df['isFraud'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    \n",
    "    X['nameOrig'] = [i[0:2] for i in X['nameOrig']]\n",
    "    X['nameDest'] = [i[0:2] for i in X['nameDest']]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(X, y, model, title=None):\n",
    "\n",
    "    # Predict probabilities on the test set\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    y_preds = model.predict(X)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = metrics.roc_auc_score(y, y_probs)\n",
    "    precision = metrics.precision_score(y, y_preds)\n",
    "    recall = metrics.recall_score(y, y_preds)\n",
    "    f1 = metrics.f1_score(y, y_preds)\n",
    "    aupr = metrics.average_precision_score(y, y_probs)\n",
    "\n",
    "    if title is None:\n",
    "        title = 'Performance metrics:'\n",
    "    else:\n",
    "        title = f'Performance metrics: {title}'\n",
    "    print(title)\n",
    "    print(\"ROC AUC:\".ljust(10) + f\"{roc_auc:.2%}\".rjust(8))\n",
    "    print(\"Precision:\".ljust(10) + f\"{precision:.2%}\".rjust(8))\n",
    "    print(\"Recall:\".ljust(10) + f\"{recall:.2%}\".rjust(8))\n",
    "    print(\"F1:\".ljust(10) + f\"{f1:.2%}\".rjust(8))\n",
    "    print(\"AUPRC:\".ljust(10) + f\"{aupr:.2%}\".rjust(8))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(encoding_method='ordered', \n",
    "                            variables=['type', 'nameOrig', 'nameDest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292779</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9914.74</td>\n",
       "      <td>4</td>\n",
       "      <td>44248.00</td>\n",
       "      <td>34333.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499763</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>6854.53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970411</th>\n",
       "      <td>231</td>\n",
       "      <td>3</td>\n",
       "      <td>361211.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>489745.16</td>\n",
       "      <td>850956.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137549</th>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>7083.51</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500682</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>218019.51</td>\n",
       "      <td>6</td>\n",
       "      <td>13045685.58</td>\n",
       "      <td>13263705.09</td>\n",
       "      <td>16</td>\n",
       "      <td>2438123.98</td>\n",
       "      <td>2220104.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type     amount  nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "292779     15     2    9914.74         4       44248.00        34333.26   \n",
       "499763     20     2    6854.53         6           0.00            0.00   \n",
       "2970411   231     3  361211.80         2           0.00            0.00   \n",
       "3137549   236     2    7083.51         6           0.00            0.00   \n",
       "1500682   143     0  218019.51         6    13045685.58     13263705.09   \n",
       "\n",
       "         nameDest  oldbalanceDest  newbalanceDest  \n",
       "292779          7            0.00            0.00  \n",
       "499763          7            0.00            0.00  \n",
       "2970411        12       489745.16       850956.95  \n",
       "3137549         7            0.00            0.00  \n",
       "1500682        16      2438123.98      2220104.47  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocessing(X_train)\n",
    "X_train = encoder.fit_transform(X_train, y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_train\n",
      "ROC AUC:   100.00%\n",
      "Precision:  98.43%\n",
      "Recall:     90.49%\n",
      "F1:         94.29%\n",
      "AUPRC:      98.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance(X_train, y_train, model, title='X_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4051353</th>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>890577.21</td>\n",
       "      <td>6</td>\n",
       "      <td>218.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>890577.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746321</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>97734.24</td>\n",
       "      <td>6</td>\n",
       "      <td>2096258.84</td>\n",
       "      <td>2193993.08</td>\n",
       "      <td>12</td>\n",
       "      <td>320136.00</td>\n",
       "      <td>222401.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361797</th>\n",
       "      <td>718</td>\n",
       "      <td>2</td>\n",
       "      <td>5907.41</td>\n",
       "      <td>6</td>\n",
       "      <td>315.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247309</th>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>187696.30</td>\n",
       "      <td>6</td>\n",
       "      <td>11057.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1798095.21</td>\n",
       "      <td>1985791.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692207</th>\n",
       "      <td>331</td>\n",
       "      <td>3</td>\n",
       "      <td>82646.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1047805.87</td>\n",
       "      <td>1130452.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type     amount  nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "4051353   300     4  890577.21         6         218.00            0.00   \n",
       "5746321   399     0   97734.24         6     2096258.84      2193993.08   \n",
       "6361797   718     2    5907.41         6         315.00            0.00   \n",
       "2247309   186     3  187696.30         6       11057.00            0.00   \n",
       "4692207   331     3   82646.52         0           0.00            0.00   \n",
       "\n",
       "         nameDest  oldbalanceDest  newbalanceDest  \n",
       "4051353        16            0.00       890577.21  \n",
       "5746321        12       320136.00       222401.76  \n",
       "6361797         7            0.00            0.00  \n",
       "2247309        12      1798095.21      1985791.51  \n",
       "4692207        12      1047805.87      1130452.39  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = preprocessing(X_test)\n",
    "X_test = encoder.transform(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_test\n",
      "ROC AUC:    99.99%\n",
      "Precision:  95.94%\n",
      "Recall:     84.84%\n",
      "F1:         90.05%\n",
      "AUPRC:      96.76%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance(X_test, y_test, model, title='X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_train\n",
      "ROC AUC:    86.04%\n",
      "Precision:  79.30%\n",
      "Recall:     44.44%\n",
      "F1:         56.96%\n",
      "AUPRC:      45.95%\n",
      "\n",
      "Performance metrics: X_test\n",
      "ROC AUC:    86.42%\n",
      "Precision:  79.63%\n",
      "Recall:     44.49%\n",
      "F1:         57.09%\n",
      "AUPRC:      46.27%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance(X_train, y_train, model_lr, title='X_train')\n",
    "performance(X_test, y_test, model_lr, title='X_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-learning pipeline & k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5090096, 9), (1272524, 9), (5090096,), (1272524,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fraud.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['isFraud', 'isFlaggedFraud'], axis=1),\n",
    "                                                    df['isFraud'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=df['isFraud'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_pipeline = Pipeline([\n",
    "    \n",
    "    # transform Origname and Destname to less granular features\n",
    "   ('orig_dest_transformation', FunctionTransformer(preprocessing)),\n",
    "\n",
    "    # categorical encoding\n",
    "    ('encoder_categorical',ce.OrdinalEncoder(encoding_method='ordered',\n",
    "                                             variables=['type', 'nameOrig', 'nameDest'])),\n",
    "    \n",
    "    # Extreme Gradiant Boosting model    \n",
    "    # ('model', XGBClassifier(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292779</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9914.74</td>\n",
       "      <td>4</td>\n",
       "      <td>44248.00</td>\n",
       "      <td>34333.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499763</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>6854.53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970411</th>\n",
       "      <td>231</td>\n",
       "      <td>3</td>\n",
       "      <td>361211.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>489745.16</td>\n",
       "      <td>850956.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137549</th>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>7083.51</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500682</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>218019.51</td>\n",
       "      <td>6</td>\n",
       "      <td>13045685.58</td>\n",
       "      <td>13263705.09</td>\n",
       "      <td>16</td>\n",
       "      <td>2438123.98</td>\n",
       "      <td>2220104.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type     amount  nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "292779     15     2    9914.74         4       44248.00        34333.26   \n",
       "499763     20     2    6854.53         6           0.00            0.00   \n",
       "2970411   231     3  361211.80         2           0.00            0.00   \n",
       "3137549   236     2    7083.51         6           0.00            0.00   \n",
       "1500682   143     0  218019.51         6    13045685.58     13263705.09   \n",
       "\n",
       "         nameDest  oldbalanceDest  newbalanceDest  \n",
       "292779          7            0.00            0.00  \n",
       "499763          7            0.00            0.00  \n",
       "2970411        12       489745.16       850956.95  \n",
       "3137549         7            0.00            0.00  \n",
       "1500682        16      2438123.98      2220104.47  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = fraud_pipeline.fit_transform(X_train, y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4051353</th>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>890577.21</td>\n",
       "      <td>6</td>\n",
       "      <td>218.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>890577.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746321</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>97734.24</td>\n",
       "      <td>6</td>\n",
       "      <td>2096258.84</td>\n",
       "      <td>2193993.08</td>\n",
       "      <td>12</td>\n",
       "      <td>320136.00</td>\n",
       "      <td>222401.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361797</th>\n",
       "      <td>718</td>\n",
       "      <td>2</td>\n",
       "      <td>5907.41</td>\n",
       "      <td>6</td>\n",
       "      <td>315.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247309</th>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>187696.30</td>\n",
       "      <td>6</td>\n",
       "      <td>11057.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1798095.21</td>\n",
       "      <td>1985791.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692207</th>\n",
       "      <td>331</td>\n",
       "      <td>3</td>\n",
       "      <td>82646.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1047805.87</td>\n",
       "      <td>1130452.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type     amount  nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "4051353   300     4  890577.21         6         218.00            0.00   \n",
       "5746321   399     0   97734.24         6     2096258.84      2193993.08   \n",
       "6361797   718     2    5907.41         6         315.00            0.00   \n",
       "2247309   186     3  187696.30         6       11057.00            0.00   \n",
       "4692207   331     3   82646.52         0           0.00            0.00   \n",
       "\n",
       "         nameDest  oldbalanceDest  newbalanceDest  \n",
       "4051353        16            0.00       890577.21  \n",
       "5746321        12       320136.00       222401.76  \n",
       "6361797         7            0.00            0.00  \n",
       "2247309        12      1798095.21      1985791.51  \n",
       "4692207        12      1047805.87      1130452.39  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = fraud_pipeline.transform(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight will be used as a hyperparameter to offset the class imbalance\n",
    "weight = int(y_train[y_train==0].shape[0] / y_train[y_train==1].shape[0])\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.11),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 2, 10),\n",
    "        'scale_pos_weight' : trial.suggest_float('scale_pos_weight', 1, weight)\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params,n_jobs=-1, random_state=42)\n",
    "\n",
    "    # Calculate F1 score using cross-validation\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    f1_mean = scores.mean()  # Take the mean F1 score\n",
    "\n",
    "    return f1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 20:54:53,652] A new study created in RDB with name: KDD_Cup_2004_1\n",
      "[I 2024-03-09 20:57:20,169] Trial 0 finished with value: 0.7595636910061376 and parameters: {'n_estimators': 250, 'learning_rate': 0.10507143064099161, 'max_depth': 8, 'scale_pos_weight': 463.16434980011223}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 20:58:10,637] Trial 1 finished with value: 0.04989737556533853 and parameters: {'n_estimators': 162, 'learning_rate': 0.025599452033620268, 'max_depth': 2, 'scale_pos_weight': 669.6879845382499}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 20:59:42,429] Trial 2 finished with value: 0.12874733437154368 and parameters: {'n_estimators': 341, 'learning_rate': 0.08080725777960454, 'max_depth': 2, 'scale_pos_weight': 749.7704058690596}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:01:54,247] Trial 3 finished with value: 0.3297701016719637 and parameters: {'n_estimators': 433, 'learning_rate': 0.031233911067827615, 'max_depth': 3, 'scale_pos_weight': 142.5882816068509}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:03:11,169] Trial 4 finished with value: 0.39874991904915075 and parameters: {'n_estimators': 222, 'learning_rate': 0.062475643163223786, 'max_depth': 5, 'scale_pos_weight': 225.82889623288835}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:04:52,873] Trial 5 finished with value: 0.2197068876367112 and parameters: {'n_estimators': 345, 'learning_rate': 0.023949386065204185, 'max_depth': 4, 'scale_pos_weight': 283.83134302273}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:06:10,409] Trial 6 finished with value: 0.2587443804457579 and parameters: {'n_estimators': 282, 'learning_rate': 0.08851759613930137, 'max_depth': 3, 'scale_pos_weight': 397.9889864553082}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:08:11,847] Trial 7 finished with value: 0.4042141159945808 and parameters: {'n_estimators': 337, 'learning_rate': 0.014645041271999773, 'max_depth': 7, 'scale_pos_weight': 132.64462348658907}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:09:15,254] Trial 8 finished with value: 0.6641065988918744 and parameters: {'n_estimators': 126, 'learning_rate': 0.10488855372533333, 'max_depth': 10, 'scale_pos_weight': 625.082752745908}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:10:46,048] Trial 9 finished with value: 0.31981716012706907 and parameters: {'n_estimators': 222, 'learning_rate': 0.01976721140063839, 'max_depth': 8, 'scale_pos_weight': 340.7977251669722}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:11:24,255] Trial 10 finished with value: 0.08514240045774815 and parameters: {'n_estimators': 148, 'learning_rate': 0.05951769101112702, 'max_depth': 2, 'scale_pos_weight': 702.9953504048198}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:12:30,921] Trial 11 finished with value: 0.2882186694413613 and parameters: {'n_estimators': 203, 'learning_rate': 0.0762522284353982, 'max_depth': 4, 'scale_pos_weight': 402.49251234926993}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:14:44,459] Trial 12 finished with value: 0.523247833809863 and parameters: {'n_estimators': 319, 'learning_rate': 0.028485445552552703, 'max_depth': 10, 'scale_pos_weight': 599.4025396347804}. Best is trial 0 with value: 0.7595636910061376.\n",
      "[I 2024-03-09 21:18:22,216] Trial 13 finished with value: 0.8048737688429796 and parameters: {'n_estimators': 476, 'learning_rate': 0.09948273504276488, 'max_depth': 7, 'scale_pos_weight': 712.6869094378462}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:18:57,960] Trial 14 finished with value: 0.14835036646560945 and parameters: {'n_estimators': 135, 'learning_rate': 0.029598286241914525, 'max_depth': 2, 'scale_pos_weight': 252.15501534924007}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:20:43,271] Trial 15 finished with value: 0.5276349376057693 and parameters: {'n_estimators': 255, 'learning_rate': 0.03713490317738959, 'max_depth': 9, 'scale_pos_weight': 276.4135682074509}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:21:43,293] Trial 16 finished with value: 0.14843228346790763 and parameters: {'n_estimators': 212, 'learning_rate': 0.06426960831582484, 'max_depth': 3, 'scale_pos_weight': 620.2960691421187}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:22:43,692] Trial 17 finished with value: 0.6616839951274051 and parameters: {'n_estimators': 129, 'learning_rate': 0.10868869366005172, 'max_depth': 8, 'scale_pos_weight': 154.4085061443811}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:23:29,005] Trial 18 finished with value: 0.4155862333810387 and parameters: {'n_estimators': 102, 'learning_rate': 0.09154614284548342, 'max_depth': 8, 'scale_pos_weight': 563.7935337276422}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:25:35,633] Trial 19 finished with value: 0.47043548631769916 and parameters: {'n_estimators': 409, 'learning_rate': 0.017404465173409038, 'max_depth': 5, 'scale_pos_weight': 90.45091395340015}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:27:54,653] Trial 20 finished with value: 0.6893748473271794 and parameters: {'n_estimators': 446, 'learning_rate': 0.07232981268275579, 'max_depth': 4, 'scale_pos_weight': 50.06704642081024}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:29:24,401] Trial 21 finished with value: 0.425417668806654 and parameters: {'n_estimators': 224, 'learning_rate': 0.04251833220267471, 'max_depth': 8, 'scale_pos_weight': 493.19436788622454}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:31:24,024] Trial 22 finished with value: 0.23725649403982646 and parameters: {'n_estimators': 455, 'learning_rate': 0.05722149251619493, 'max_depth': 3, 'scale_pos_weight': 551.6249757361521}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:34:37,336] Trial 23 finished with value: 0.7649011518363513 and parameters: {'n_estimators': 405, 'learning_rate': 0.06612771975694963, 'max_depth': 8, 'scale_pos_weight': 382.21020039330966}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:35:47,606] Trial 24 finished with value: 0.41059979282156644 and parameters: {'n_estimators': 309, 'learning_rate': 0.052754101835854966, 'max_depth': 2, 'scale_pos_weight': 84.29218163883104}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:36:26,618] Trial 25 finished with value: 0.1879774715175567 and parameters: {'n_estimators': 112, 'learning_rate': 0.07364104112637804, 'max_depth': 4, 'scale_pos_weight': 393.61657357915055}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:38:58,563] Trial 26 finished with value: 0.33929922083513503 and parameters: {'n_estimators': 463, 'learning_rate': 0.034929222914887495, 'max_depth': 5, 'scale_pos_weight': 584.2854789552335}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:39:57,539] Trial 27 finished with value: 0.39476100856859153 and parameters: {'n_estimators': 191, 'learning_rate': 0.0176979909828793, 'max_depth': 4, 'scale_pos_weight': 125.46283376009141}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:43:31,426] Trial 28 finished with value: 0.7844242874564464 and parameters: {'n_estimators': 472, 'learning_rate': 0.0908120379564417, 'max_depth': 7, 'scale_pos_weight': 673.7675756249181}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:46:36,282] Trial 29 finished with value: 0.6417089998167826 and parameters: {'n_estimators': 422, 'learning_rate': 0.028657005888603586, 'max_depth': 10, 'scale_pos_weight': 417.3722107588824}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:48:48,755] Trial 30 finished with value: 0.6540618308627136 and parameters: {'n_estimators': 423, 'learning_rate': 0.09960912999234932, 'max_depth': 4, 'scale_pos_weight': 85.96008573536646}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:50:09,918] Trial 31 finished with value: 0.4928620589967066 and parameters: {'n_estimators': 191, 'learning_rate': 0.05271077886262564, 'max_depth': 9, 'scale_pos_weight': 665.4840102738972}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:50:47,892] Trial 32 finished with value: 0.3240311434197016 and parameters: {'n_estimators': 102, 'learning_rate': 0.06107473025775658, 'max_depth': 5, 'scale_pos_weight': 172.46722968340376}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:51:53,821] Trial 33 finished with value: 0.5005584068786992 and parameters: {'n_estimators': 148, 'learning_rate': 0.0437615171403628, 'max_depth': 10, 'scale_pos_weight': 250.51266352002304}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:53:43,472] Trial 34 finished with value: 0.4441005918417586 and parameters: {'n_estimators': 308, 'learning_rate': 0.08030189588951778, 'max_depth': 5, 'scale_pos_weight': 751.2157678605816}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:56:43,513] Trial 35 finished with value: 0.5385773757636925 and parameters: {'n_estimators': 485, 'learning_rate': 0.03517822958253642, 'max_depth': 6, 'scale_pos_weight': 233.27805517854617}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:58:05,677] Trial 36 finished with value: 0.22837656593002223 and parameters: {'n_estimators': 214, 'learning_rate': 0.01368869473545328, 'max_depth': 7, 'scale_pos_weight': 389.06820593268105}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 21:59:00,680] Trial 37 finished with value: 0.47975464049089345 and parameters: {'n_estimators': 120, 'learning_rate': 0.03786464642366114, 'max_depth': 10, 'scale_pos_weight': 185.9417795949027}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 22:00:11,305] Trial 38 finished with value: 0.6066630917955189 and parameters: {'n_estimators': 158, 'learning_rate': 0.05894527602775631, 'max_depth': 10, 'scale_pos_weight': 187.86666960687833}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 22:02:06,658] Trial 39 finished with value: 0.4026843376111239 and parameters: {'n_estimators': 369, 'learning_rate': 0.08616196153287176, 'max_depth': 4, 'scale_pos_weight': 563.1830211283556}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 22:03:51,954] Trial 40 finished with value: 0.5953046302951578 and parameters: {'n_estimators': 247, 'learning_rate': 0.07323058305935795, 'max_depth': 7, 'scale_pos_weight': 414.61805610571355}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 22:04:39,121] Trial 41 finished with value: 0.37886355495426616 and parameters: {'n_estimators': 136, 'learning_rate': 0.09353024955892379, 'max_depth': 4, 'scale_pos_weight': 144.99229002868748}. Best is trial 13 with value: 0.8048737688429796.\n",
      "[I 2024-03-09 22:05:27,557] Trial 42 finished with value: 0.8446320214716228 and parameters: {'n_estimators': 116, 'learning_rate': 0.06908929431882418, 'max_depth': 8, 'scale_pos_weight': 13.805803932304949}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:07:19,468] Trial 43 finished with value: 0.5149736422858349 and parameters: {'n_estimators': 305, 'learning_rate': 0.0326495775197938, 'max_depth': 7, 'scale_pos_weight': 135.6108831918534}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:10:28,808] Trial 44 finished with value: 0.823082750074921 and parameters: {'n_estimators': 377, 'learning_rate': 0.04867353463005374, 'max_depth': 10, 'scale_pos_weight': 107.16616888070679}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:12:09,200] Trial 45 finished with value: 0.3946802057750373 and parameters: {'n_estimators': 236, 'learning_rate': 0.02134735212405891, 'max_depth': 10, 'scale_pos_weight': 678.3059808101174}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:13:46,423] Trial 46 finished with value: 0.679501973024651 and parameters: {'n_estimators': 203, 'learning_rate': 0.0759984046034179, 'max_depth': 9, 'scale_pos_weight': 429.6150265547849}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:14:57,447] Trial 47 finished with value: 0.0930355679121784 and parameters: {'n_estimators': 312, 'learning_rate': 0.03418522909004517, 'max_depth': 2, 'scale_pos_weight': 693.6505651399683}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:17:40,522] Trial 48 finished with value: 0.5977729625423647 and parameters: {'n_estimators': 461, 'learning_rate': 0.07331014572732679, 'max_depth': 5, 'scale_pos_weight': 270.5897916009742}. Best is trial 42 with value: 0.8446320214716228.\n",
      "[I 2024-03-09 22:21:08,488] Trial 49 finished with value: 0.8494033657351959 and parameters: {'n_estimators': 391, 'learning_rate': 0.0997110259952577, 'max_depth': 9, 'scale_pos_weight': 603.0639214020856}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:22:42,595] Trial 50 finished with value: 0.10246366430511566 and parameters: {'n_estimators': 357, 'learning_rate': 0.018413996499504884, 'max_depth': 3, 'scale_pos_weight': 694.6838335429052}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:23:58,685] Trial 51 finished with value: 0.07163122817891683 and parameters: {'n_estimators': 343, 'learning_rate': 0.010919705161662964, 'max_depth': 2, 'scale_pos_weight': 513.2233657514191}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:24:39,857] Trial 52 finished with value: 0.17287434828250384 and parameters: {'n_estimators': 102, 'learning_rate': 0.026080805141749867, 'max_depth': 6, 'scale_pos_weight': 535.1430926187592}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:27:04,765] Trial 53 finished with value: 0.5792485478839019 and parameters: {'n_estimators': 361, 'learning_rate': 0.03242693094605598, 'max_depth': 8, 'scale_pos_weight': 184.15629554752965}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:28:45,147] Trial 54 finished with value: 0.5915453282777192 and parameters: {'n_estimators': 230, 'learning_rate': 0.08464914051180242, 'max_depth': 7, 'scale_pos_weight': 656.6004729015053}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:30:05,413] Trial 55 finished with value: 0.20175685723056308 and parameters: {'n_estimators': 363, 'learning_rate': 0.06683086033354717, 'max_depth': 2, 'scale_pos_weight': 284.8765999618827}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:31:33,875] Trial 56 finished with value: 0.5008487119995836 and parameters: {'n_estimators': 206, 'learning_rate': 0.03439896433790836, 'max_depth': 10, 'scale_pos_weight': 304.47144344273903}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:35:31,205] Trial 57 finished with value: 0.8391030481658346 and parameters: {'n_estimators': 457, 'learning_rate': 0.07311386259972628, 'max_depth': 9, 'scale_pos_weight': 389.0358358772083}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:37:00,561] Trial 58 finished with value: 0.19858974429073542 and parameters: {'n_estimators': 331, 'learning_rate': 0.05925176938188639, 'max_depth': 3, 'scale_pos_weight': 558.7330329818822}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:38:22,451] Trial 59 finished with value: 0.38683872739518504 and parameters: {'n_estimators': 212, 'learning_rate': 0.012431596643145384, 'max_depth': 7, 'scale_pos_weight': 137.7294445022418}. Best is trial 49 with value: 0.8494033657351959.\n",
      "[I 2024-03-09 22:42:49,068] Trial 60 finished with value: 0.8854823732036611 and parameters: {'n_estimators': 477, 'learning_rate': 0.10539285770025873, 'max_depth': 10, 'scale_pos_weight': 286.76251659720305}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:43:30,024] Trial 61 finished with value: 0.2542296639426625 and parameters: {'n_estimators': 106, 'learning_rate': 0.10283185625877254, 'max_depth': 5, 'scale_pos_weight': 747.2575203017129}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:46:01,799] Trial 62 finished with value: 0.5400743218755537 and parameters: {'n_estimators': 486, 'learning_rate': 0.095300945546736, 'max_depth': 4, 'scale_pos_weight': 298.2954464806863}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:47:56,066] Trial 63 finished with value: 0.20483523804291673 and parameters: {'n_estimators': 441, 'learning_rate': 0.04169220051562777, 'max_depth': 3, 'scale_pos_weight': 430.8505746178463}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:51:26,772] Trial 64 finished with value: 0.8345603086420763 and parameters: {'n_estimators': 475, 'learning_rate': 0.0796029796674973, 'max_depth': 7, 'scale_pos_weight': 76.0202531910333}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:52:59,628] Trial 65 finished with value: 0.3223032622457036 and parameters: {'n_estimators': 346, 'learning_rate': 0.10900538501042632, 'max_depth': 3, 'scale_pos_weight': 401.1504916248048}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:56:44,260] Trial 66 finished with value: 0.8193392908579817 and parameters: {'n_estimators': 451, 'learning_rate': 0.08407686177542044, 'max_depth': 8, 'scale_pos_weight': 543.3177128380484}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 22:58:25,008] Trial 67 finished with value: 0.47902835053855225 and parameters: {'n_estimators': 244, 'learning_rate': 0.03935918442644934, 'max_depth': 9, 'scale_pos_weight': 626.4075406923275}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:01:27,912] Trial 68 finished with value: 0.7512249003397555 and parameters: {'n_estimators': 447, 'learning_rate': 0.10132405525564712, 'max_depth': 6, 'scale_pos_weight': 388.1705794985181}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:04:51,601] Trial 69 finished with value: 0.7848004908271566 and parameters: {'n_estimators': 420, 'learning_rate': 0.07499639307777652, 'max_depth': 8, 'scale_pos_weight': 615.35194080467}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:07:26,474] Trial 70 finished with value: 0.627703024352513 and parameters: {'n_estimators': 456, 'learning_rate': 0.043799515685153584, 'max_depth': 5, 'scale_pos_weight': 73.55405755715087}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:09:14,439] Trial 71 finished with value: 0.2291202397231605 and parameters: {'n_estimators': 331, 'learning_rate': 0.01359422737967421, 'max_depth': 6, 'scale_pos_weight': 419.92165799424913}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:10:07,098] Trial 72 finished with value: 0.6181186653088627 and parameters: {'n_estimators': 214, 'learning_rate': 0.06908332605690108, 'max_depth': 2, 'scale_pos_weight': 29.83280171439353}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:11:58,912] Trial 73 finished with value: 0.22463727882553558 and parameters: {'n_estimators': 429, 'learning_rate': 0.04601906414112629, 'max_depth': 3, 'scale_pos_weight': 404.171796762309}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:14:36,431] Trial 74 finished with value: 0.6812085510954298 and parameters: {'n_estimators': 408, 'learning_rate': 0.03158210274968432, 'max_depth': 7, 'scale_pos_weight': 66.88824297518889}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:15:21,692] Trial 75 finished with value: 0.258772338856717 and parameters: {'n_estimators': 120, 'learning_rate': 0.0631354631568148, 'max_depth': 6, 'scale_pos_weight': 493.09588395661547}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:18:01,871] Trial 76 finished with value: 0.7539642475472059 and parameters: {'n_estimators': 391, 'learning_rate': 0.10758520794625347, 'max_depth': 6, 'scale_pos_weight': 250.32239711064187}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:20:20,243] Trial 77 finished with value: 0.6166342275494902 and parameters: {'n_estimators': 418, 'learning_rate': 0.037083225126207424, 'max_depth': 5, 'scale_pos_weight': 61.56832639622932}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:21:12,935] Trial 78 finished with value: 0.5692819340189151 and parameters: {'n_estimators': 110, 'learning_rate': 0.10626484146779251, 'max_depth': 9, 'scale_pos_weight': 538.2920871043349}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:22:24,681] Trial 79 finished with value: 0.2534552917102678 and parameters: {'n_estimators': 263, 'learning_rate': 0.027329432007084577, 'max_depth': 3, 'scale_pos_weight': 194.1875173830676}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:24:46,664] Trial 80 finished with value: 0.7288640345835443 and parameters: {'n_estimators': 320, 'learning_rate': 0.08145959227000624, 'max_depth': 7, 'scale_pos_weight': 217.10896844226787}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:28:01,159] Trial 81 finished with value: 0.7160232718029891 and parameters: {'n_estimators': 482, 'learning_rate': 0.08378969166957685, 'max_depth': 6, 'scale_pos_weight': 473.2484160929199}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:29:27,640] Trial 82 finished with value: 0.23323543300930094 and parameters: {'n_estimators': 268, 'learning_rate': 0.034773098950115745, 'max_depth': 5, 'scale_pos_weight': 586.0571972784929}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:29:56,820] Trial 83 finished with value: 0.7100071298237106 and parameters: {'n_estimators': 105, 'learning_rate': 0.021607264050691626, 'max_depth': 2, 'scale_pos_weight': 32.442635390244945}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:32:53,938] Trial 84 finished with value: 0.7863374433567419 and parameters: {'n_estimators': 443, 'learning_rate': 0.08036578593800237, 'max_depth': 6, 'scale_pos_weight': 76.52797202257314}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:34:13,202] Trial 85 finished with value: 0.2214459082396596 and parameters: {'n_estimators': 297, 'learning_rate': 0.057347177078056574, 'max_depth': 3, 'scale_pos_weight': 335.9334732117152}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:36:03,389] Trial 86 finished with value: 0.7985644927862081 and parameters: {'n_estimators': 259, 'learning_rate': 0.07158500980522164, 'max_depth': 7, 'scale_pos_weight': 35.97469554401837}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:37:41,715] Trial 87 finished with value: 0.4726198029331747 and parameters: {'n_estimators': 250, 'learning_rate': 0.07258599157142363, 'max_depth': 6, 'scale_pos_weight': 662.2101573973848}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:39:02,436] Trial 88 finished with value: 0.10653397470196031 and parameters: {'n_estimators': 364, 'learning_rate': 0.026293442708142968, 'max_depth': 2, 'scale_pos_weight': 496.94768277527567}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:39:54,136] Trial 89 finished with value: 0.4897970882167281 and parameters: {'n_estimators': 110, 'learning_rate': 0.06857755812734632, 'max_depth': 10, 'scale_pos_weight': 445.26606532017854}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:41:34,449] Trial 90 finished with value: 0.5177028752334583 and parameters: {'n_estimators': 255, 'learning_rate': 0.07432882184423531, 'max_depth': 6, 'scale_pos_weight': 422.21616135190175}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:45:46,163] Trial 91 finished with value: 0.803302961478866 and parameters: {'n_estimators': 477, 'learning_rate': 0.04861026378007743, 'max_depth': 10, 'scale_pos_weight': 699.9306955900812}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:46:29,758] Trial 92 finished with value: 0.7108330561929967 and parameters: {'n_estimators': 178, 'learning_rate': 0.016936130087516547, 'max_depth': 2, 'scale_pos_weight': 15.06724940299639}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:47:06,231] Trial 93 finished with value: 0.18395082783602895 and parameters: {'n_estimators': 137, 'learning_rate': 0.07830067734163568, 'max_depth': 2, 'scale_pos_weight': 247.24918658678374}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:49:58,400] Trial 94 finished with value: 0.4435248098061734 and parameters: {'n_estimators': 438, 'learning_rate': 0.012327193573582588, 'max_depth': 9, 'scale_pos_weight': 218.59188612506475}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:50:59,495] Trial 95 finished with value: 0.4198025860447313 and parameters: {'n_estimators': 147, 'learning_rate': 0.07967371653641506, 'max_depth': 7, 'scale_pos_weight': 678.4083944428849}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:53:02,184] Trial 96 finished with value: 0.5617228532688225 and parameters: {'n_estimators': 394, 'learning_rate': 0.09034809303848486, 'max_depth': 4, 'scale_pos_weight': 137.983327797946}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:56:47,333] Trial 97 finished with value: 0.8709425618521532 and parameters: {'n_estimators': 400, 'learning_rate': 0.0906834739267264, 'max_depth': 10, 'scale_pos_weight': 319.54084657562123}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-09 23:58:16,928] Trial 98 finished with value: 0.4111300768746119 and parameters: {'n_estimators': 249, 'learning_rate': 0.08764129607419968, 'max_depth': 5, 'scale_pos_weight': 719.5446553659519}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:01:42,840] Trial 99 finished with value: 0.715782885991268 and parameters: {'n_estimators': 444, 'learning_rate': 0.05289940273750184, 'max_depth': 8, 'scale_pos_weight': 583.5070987933748}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:02:40,069] Trial 100 finished with value: 0.4082395606144136 and parameters: {'n_estimators': 141, 'learning_rate': 0.10025529066795667, 'max_depth': 6, 'scale_pos_weight': 639.0251638351765}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:04:01,932] Trial 101 finished with value: 0.8785431194336148 and parameters: {'n_estimators': 228, 'learning_rate': 0.09955232284962005, 'max_depth': 5, 'scale_pos_weight': 9.366666942790335}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:06:15,090] Trial 102 finished with value: 0.14602231437318983 and parameters: {'n_estimators': 463, 'learning_rate': 0.019128667678613355, 'max_depth': 4, 'scale_pos_weight': 734.4478385632214}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:09:46,726] Trial 103 finished with value: 0.7546923273855963 and parameters: {'n_estimators': 481, 'learning_rate': 0.06734378881232861, 'max_depth': 7, 'scale_pos_weight': 347.19994296726287}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:11:13,200] Trial 104 finished with value: 0.400500438680537 and parameters: {'n_estimators': 217, 'learning_rate': 0.0428664545369916, 'max_depth': 8, 'scale_pos_weight': 581.833136725889}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:12:43,895] Trial 105 finished with value: 0.20304999125118767 and parameters: {'n_estimators': 417, 'learning_rate': 0.08896181427945539, 'max_depth': 2, 'scale_pos_weight': 382.6924752303929}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:13:27,421] Trial 106 finished with value: 0.19908213993669777 and parameters: {'n_estimators': 123, 'learning_rate': 0.06495288823237355, 'max_depth': 5, 'scale_pos_weight': 686.3076290894074}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:14:33,960] Trial 107 finished with value: 0.10338036398798726 and parameters: {'n_estimators': 240, 'learning_rate': 0.02170670164276059, 'max_depth': 3, 'scale_pos_weight': 588.8862076858886}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:15:51,547] Trial 108 finished with value: 0.09018456875937225 and parameters: {'n_estimators': 347, 'learning_rate': 0.020112267612279026, 'max_depth': 2, 'scale_pos_weight': 542.1481694864407}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:16:49,557] Trial 109 finished with value: 0.7117590961866995 and parameters: {'n_estimators': 129, 'learning_rate': 0.09218600592903563, 'max_depth': 8, 'scale_pos_weight': 63.80125865554662}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:17:40,063] Trial 110 finished with value: 0.39389900867770933 and parameters: {'n_estimators': 134, 'learning_rate': 0.10866395785011755, 'max_depth': 5, 'scale_pos_weight': 287.1357375356398}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:21:39,921] Trial 111 finished with value: 0.8734214918015066 and parameters: {'n_estimators': 425, 'learning_rate': 0.10472485773838587, 'max_depth': 10, 'scale_pos_weight': 582.607959019903}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:23:18,868] Trial 112 finished with value: 0.3039792357550087 and parameters: {'n_estimators': 250, 'learning_rate': 0.018350071669866876, 'max_depth': 8, 'scale_pos_weight': 432.0880807960415}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:24:33,006] Trial 113 finished with value: 0.27569443082998885 and parameters: {'n_estimators': 270, 'learning_rate': 0.1006354385094736, 'max_depth': 3, 'scale_pos_weight': 381.3065805125433}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:25:02,466] Trial 114 finished with value: 0.3821487520667444 and parameters: {'n_estimators': 104, 'learning_rate': 0.05686606419941263, 'max_depth': 2, 'scale_pos_weight': 92.72743135895152}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:26:06,102] Trial 115 finished with value: 0.4946162771205027 and parameters: {'n_estimators': 147, 'learning_rate': 0.07492103021160636, 'max_depth': 8, 'scale_pos_weight': 451.3606866550072}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:28:33,125] Trial 116 finished with value: 0.3145280736407902 and parameters: {'n_estimators': 485, 'learning_rate': 0.04748705795237041, 'max_depth': 4, 'scale_pos_weight': 671.5585269622634}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:29:18,989] Trial 117 finished with value: 0.11221089643819096 and parameters: {'n_estimators': 189, 'learning_rate': 0.10632225394406113, 'max_depth': 2, 'scale_pos_weight': 749.7464542182973}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:30:06,809] Trial 118 finished with value: 0.3328021300400942 and parameters: {'n_estimators': 117, 'learning_rate': 0.09911431136980711, 'max_depth': 6, 'scale_pos_weight': 767.5688226040999}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:31:05,426] Trial 119 finished with value: 0.5236005548315681 and parameters: {'n_estimators': 129, 'learning_rate': 0.06538542844013208, 'max_depth': 10, 'scale_pos_weight': 404.8315356993549}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:33:26,150] Trial 120 finished with value: 0.6201423430824722 and parameters: {'n_estimators': 352, 'learning_rate': 0.07957486889846171, 'max_depth': 6, 'scale_pos_weight': 485.47483782489695}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:34:40,661] Trial 121 finished with value: 0.2664117529474385 and parameters: {'n_estimators': 334, 'learning_rate': 0.1001158010490989, 'max_depth': 2, 'scale_pos_weight': 217.9035823652018}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:37:56,665] Trial 122 finished with value: 0.7527710687164063 and parameters: {'n_estimators': 481, 'learning_rate': 0.09902637838909163, 'max_depth': 6, 'scale_pos_weight': 479.74236550278636}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:39:08,189] Trial 123 finished with value: 0.28600827863758466 and parameters: {'n_estimators': 211, 'learning_rate': 0.02881211597237613, 'max_depth': 6, 'scale_pos_weight': 273.7879200361128}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:41:26,290] Trial 124 finished with value: 0.41277358934795216 and parameters: {'n_estimators': 334, 'learning_rate': 0.017773463696498484, 'max_depth': 10, 'scale_pos_weight': 762.3546947382534}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:43:22,953] Trial 125 finished with value: 0.32544951111265263 and parameters: {'n_estimators': 379, 'learning_rate': 0.06360963663441203, 'max_depth': 4, 'scale_pos_weight': 629.2497552137644}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:45:58,456] Trial 126 finished with value: 0.5405864443418442 and parameters: {'n_estimators': 374, 'learning_rate': 0.026261693934489128, 'max_depth': 10, 'scale_pos_weight': 635.9987515366864}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:49:33,493] Trial 127 finished with value: 0.7905860690984923 and parameters: {'n_estimators': 480, 'learning_rate': 0.08257195083883599, 'max_depth': 7, 'scale_pos_weight': 323.88362401635777}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:51:16,226] Trial 128 finished with value: 0.7378630325425036 and parameters: {'n_estimators': 474, 'learning_rate': 0.09660638895004084, 'max_depth': 2, 'scale_pos_weight': 21.355304311878548}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:53:30,966] Trial 129 finished with value: 0.8473700855465474 and parameters: {'n_estimators': 250, 'learning_rate': 0.0910553330781833, 'max_depth': 10, 'scale_pos_weight': 117.12183993192376}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:56:17,374] Trial 130 finished with value: 0.7237833436727417 and parameters: {'n_estimators': 338, 'learning_rate': 0.04808908566310215, 'max_depth': 10, 'scale_pos_weight': 651.1158086607671}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:58:48,746] Trial 131 finished with value: 0.5435701533098003 and parameters: {'n_estimators': 436, 'learning_rate': 0.056869315979497036, 'max_depth': 5, 'scale_pos_weight': 212.0702595305052}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 00:59:46,006] Trial 132 finished with value: 0.5588250205491574 and parameters: {'n_estimators': 122, 'learning_rate': 0.09647223762550532, 'max_depth': 9, 'scale_pos_weight': 772.7820437768928}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:03:47,112] Trial 133 finished with value: 0.7856469792386644 and parameters: {'n_estimators': 499, 'learning_rate': 0.06554317056026275, 'max_depth': 8, 'scale_pos_weight': 730.3591434692345}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:06:31,495] Trial 134 finished with value: 0.6086687241193613 and parameters: {'n_estimators': 440, 'learning_rate': 0.034734810174319765, 'max_depth': 6, 'scale_pos_weight': 100.71106849695413}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:09:00,301] Trial 135 finished with value: 0.4217342918105517 and parameters: {'n_estimators': 482, 'learning_rate': 0.070617463445088, 'max_depth': 4, 'scale_pos_weight': 519.5529283613214}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:10:32,403] Trial 136 finished with value: 0.17280658833158008 and parameters: {'n_estimators': 347, 'learning_rate': 0.045816271803284056, 'max_depth': 3, 'scale_pos_weight': 519.4545069976413}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:12:36,974] Trial 137 finished with value: 0.58847462183325 and parameters: {'n_estimators': 308, 'learning_rate': 0.08723183917356393, 'max_depth': 6, 'scale_pos_weight': 658.884118245913}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:15:16,549] Trial 138 finished with value: 0.7750013060777644 and parameters: {'n_estimators': 321, 'learning_rate': 0.06609379715353862, 'max_depth': 9, 'scale_pos_weight': 312.4887727159705}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:16:21,229] Trial 139 finished with value: 0.2310295175635626 and parameters: {'n_estimators': 153, 'learning_rate': 0.012878267631333897, 'max_depth': 8, 'scale_pos_weight': 479.8789736448747}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:17:58,906] Trial 140 finished with value: 0.8108080148865009 and parameters: {'n_estimators': 382, 'learning_rate': 0.03129641615089108, 'max_depth': 3, 'scale_pos_weight': 12.22848189560485}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:19:22,828] Trial 141 finished with value: 0.39470061025349273 and parameters: {'n_estimators': 240, 'learning_rate': 0.0689917686854633, 'max_depth': 5, 'scale_pos_weight': 338.7306398023188}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:22:19,034] Trial 142 finished with value: 0.5069865414001524 and parameters: {'n_estimators': 462, 'learning_rate': 0.044825546702330035, 'max_depth': 6, 'scale_pos_weight': 605.9801258361624}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:24:25,899] Trial 143 finished with value: 0.7114648679753268 and parameters: {'n_estimators': 259, 'learning_rate': 0.07220867002278734, 'max_depth': 9, 'scale_pos_weight': 734.0299214636997}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:25:30,749] Trial 144 finished with value: 0.5492603921906027 and parameters: {'n_estimators': 158, 'learning_rate': 0.10265876251614944, 'max_depth': 6, 'scale_pos_weight': 200.36466776679583}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:27:26,596] Trial 145 finished with value: 0.6847619152871934 and parameters: {'n_estimators': 284, 'learning_rate': 0.10800325752854771, 'max_depth': 6, 'scale_pos_weight': 254.79624314195635}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:28:44,968] Trial 146 finished with value: 0.3552897409019954 and parameters: {'n_estimators': 353, 'learning_rate': 0.03401456187781931, 'max_depth': 2, 'scale_pos_weight': 100.4951453150212}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:29:29,811] Trial 147 finished with value: 0.10303015732588719 and parameters: {'n_estimators': 151, 'learning_rate': 0.025190269351229436, 'max_depth': 3, 'scale_pos_weight': 495.75530298808167}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:30:45,344] Trial 148 finished with value: 0.5064873450930552 and parameters: {'n_estimators': 172, 'learning_rate': 0.04456672833238633, 'max_depth': 10, 'scale_pos_weight': 366.89838628293745}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:32:20,358] Trial 149 finished with value: 0.6507532847439357 and parameters: {'n_estimators': 367, 'learning_rate': 0.027231987120162983, 'max_depth': 3, 'scale_pos_weight': 32.550571757721684}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:33:08,738] Trial 150 finished with value: 0.5220297254716579 and parameters: {'n_estimators': 167, 'learning_rate': 0.037859033903195866, 'max_depth': 3, 'scale_pos_weight': 69.47835606044693}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:33:52,431] Trial 151 finished with value: 0.1911862648173685 and parameters: {'n_estimators': 148, 'learning_rate': 0.05607787680327258, 'max_depth': 3, 'scale_pos_weight': 282.21633272911424}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:35:00,543] Trial 152 finished with value: 0.13004255835591177 and parameters: {'n_estimators': 301, 'learning_rate': 0.07903948286293652, 'max_depth': 2, 'scale_pos_weight': 618.1448279577809}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:37:21,653] Trial 153 finished with value: 0.3874561989698466 and parameters: {'n_estimators': 351, 'learning_rate': 0.01817590319488719, 'max_depth': 9, 'scale_pos_weight': 711.9134932105597}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:38:17,609] Trial 154 finished with value: 0.3432427899953316 and parameters: {'n_estimators': 124, 'learning_rate': 0.03768776481472037, 'max_depth': 9, 'scale_pos_weight': 578.6564809761843}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:39:14,655] Trial 155 finished with value: 0.20315936968781895 and parameters: {'n_estimators': 173, 'learning_rate': 0.030934932333671034, 'max_depth': 5, 'scale_pos_weight': 375.05174456746846}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:41:25,467] Trial 156 finished with value: 0.44373289650417747 and parameters: {'n_estimators': 347, 'learning_rate': 0.046891363956977246, 'max_depth': 6, 'scale_pos_weight': 578.04756423926}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:42:15,583] Trial 157 finished with value: 0.25972596319050273 and parameters: {'n_estimators': 114, 'learning_rate': 0.035243694434402076, 'max_depth': 8, 'scale_pos_weight': 692.0996786945179}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:43:25,087] Trial 158 finished with value: 0.16485102066540397 and parameters: {'n_estimators': 305, 'learning_rate': 0.06321134852653157, 'max_depth': 2, 'scale_pos_weight': 346.402347187707}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:44:59,763] Trial 159 finished with value: 0.253010438954391 and parameters: {'n_estimators': 313, 'learning_rate': 0.03424705036347297, 'max_depth': 4, 'scale_pos_weight': 292.26337391676867}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:45:34,059] Trial 160 finished with value: 0.1857497652459741 and parameters: {'n_estimators': 108, 'learning_rate': 0.042207916558317835, 'max_depth': 3, 'scale_pos_weight': 253.8279558813501}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:46:39,299] Trial 161 finished with value: 0.5230140098483543 and parameters: {'n_estimators': 148, 'learning_rate': 0.0990527280739895, 'max_depth': 7, 'scale_pos_weight': 525.266990379546}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:48:09,711] Trial 162 finished with value: 0.16254923411177055 and parameters: {'n_estimators': 416, 'learning_rate': 0.05984421989290573, 'max_depth': 2, 'scale_pos_weight': 415.6462502839189}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:50:08,438] Trial 163 finished with value: 0.6564171236463586 and parameters: {'n_estimators': 335, 'learning_rate': 0.08454394741843299, 'max_depth': 5, 'scale_pos_weight': 99.49199375817523}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:51:29,847] Trial 164 finished with value: 0.3890324936565802 and parameters: {'n_estimators': 213, 'learning_rate': 0.046308229639863516, 'max_depth': 7, 'scale_pos_weight': 441.64085120439995}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:53:18,985] Trial 165 finished with value: 0.741583841863849 and parameters: {'n_estimators': 242, 'learning_rate': 0.10865152487929797, 'max_depth': 7, 'scale_pos_weight': 184.13908322018773}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:54:04,855] Trial 166 finished with value: 0.3904993739577651 and parameters: {'n_estimators': 140, 'learning_rate': 0.025285913918433205, 'max_depth': 4, 'scale_pos_weight': 125.04602015637698}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:54:55,418] Trial 167 finished with value: 0.10375924788602522 and parameters: {'n_estimators': 174, 'learning_rate': 0.03850951686938471, 'max_depth': 3, 'scale_pos_weight': 693.3029078116002}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:55:42,699] Trial 168 finished with value: 0.19353320418951453 and parameters: {'n_estimators': 132, 'learning_rate': 0.06245113895702547, 'max_depth': 5, 'scale_pos_weight': 759.3962922534441}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:56:47,623] Trial 169 finished with value: 0.4650079960843433 and parameters: {'n_estimators': 144, 'learning_rate': 0.049785559904574166, 'max_depth': 10, 'scale_pos_weight': 669.1715011901528}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 01:58:38,673] Trial 170 finished with value: 0.1683267071289829 and parameters: {'n_estimators': 427, 'learning_rate': 0.035790282704493984, 'max_depth': 3, 'scale_pos_weight': 517.1925657816607}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:02:06,138] Trial 171 finished with value: 0.7618644179057619 and parameters: {'n_estimators': 472, 'learning_rate': 0.06567628930139298, 'max_depth': 7, 'scale_pos_weight': 217.1438603057394}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:04:06,970] Trial 172 finished with value: 0.25130940756140335 and parameters: {'n_estimators': 408, 'learning_rate': 0.028704374855752335, 'max_depth': 4, 'scale_pos_weight': 329.4369306118738}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:05:27,875] Trial 173 finished with value: 0.14758390880168887 and parameters: {'n_estimators': 303, 'learning_rate': 0.03424097324150802, 'max_depth': 3, 'scale_pos_weight': 472.3986727649404}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:06:28,009] Trial 174 finished with value: 0.1945176632626087 and parameters: {'n_estimators': 215, 'learning_rate': 0.06812382214226123, 'max_depth': 3, 'scale_pos_weight': 372.4401586319191}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:08:05,205] Trial 175 finished with value: 0.4221559542766199 and parameters: {'n_estimators': 313, 'learning_rate': 0.015182353682242692, 'max_depth': 5, 'scale_pos_weight': 104.76813059688811}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:08:48,841] Trial 176 finished with value: 0.2275518931660779 and parameters: {'n_estimators': 125, 'learning_rate': 0.10899602323899453, 'max_depth': 4, 'scale_pos_weight': 626.2230721997781}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:10:21,098] Trial 177 finished with value: 0.6190155710689212 and parameters: {'n_estimators': 202, 'learning_rate': 0.07815027222239293, 'max_depth': 8, 'scale_pos_weight': 460.83310774925576}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:11:59,283] Trial 178 finished with value: 0.3090173974567427 and parameters: {'n_estimators': 289, 'learning_rate': 0.05118409141472686, 'max_depth': 5, 'scale_pos_weight': 718.5964993593216}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:13:54,429] Trial 179 finished with value: 0.337393438197337 and parameters: {'n_estimators': 433, 'learning_rate': 0.10650269106665126, 'max_depth': 3, 'scale_pos_weight': 565.2296908572133}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:15:38,407] Trial 180 finished with value: 0.11052050888257978 and parameters: {'n_estimators': 476, 'learning_rate': 0.028123306616566014, 'max_depth': 2, 'scale_pos_weight': 573.1451412519256}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:17:10,032] Trial 181 finished with value: 0.2582863240916854 and parameters: {'n_estimators': 330, 'learning_rate': 0.09418287767582721, 'max_depth': 3, 'scale_pos_weight': 614.9463647558352}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:18:02,209] Trial 182 finished with value: 0.0967541789941075 and parameters: {'n_estimators': 180, 'learning_rate': 0.026365594286570454, 'max_depth': 3, 'scale_pos_weight': 629.851684018627}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:20:10,668] Trial 183 finished with value: 0.4240495144552832 and parameters: {'n_estimators': 366, 'learning_rate': 0.06230654247691194, 'max_depth': 5, 'scale_pos_weight': 678.1988175077196}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:21:43,486] Trial 184 finished with value: 0.5018227881642691 and parameters: {'n_estimators': 257, 'learning_rate': 0.09165994394715771, 'max_depth': 5, 'scale_pos_weight': 292.00109951602866}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:23:38,437] Trial 185 finished with value: 0.5057441583952851 and parameters: {'n_estimators': 285, 'learning_rate': 0.04013778741641421, 'max_depth': 8, 'scale_pos_weight': 389.1001411513939}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:24:49,686] Trial 186 finished with value: 0.4229952559953615 and parameters: {'n_estimators': 193, 'learning_rate': 0.09995745732745685, 'max_depth': 5, 'scale_pos_weight': 420.6228087799992}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:26:51,594] Trial 187 finished with value: 0.2546812943384464 and parameters: {'n_estimators': 463, 'learning_rate': 0.0724237995913992, 'max_depth': 3, 'scale_pos_weight': 726.5503994296027}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:28:24,753] Trial 188 finished with value: 0.15884599844914887 and parameters: {'n_estimators': 351, 'learning_rate': 0.043490561465708615, 'max_depth': 3, 'scale_pos_weight': 613.9874461166685}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:31:28,870] Trial 189 finished with value: 0.7973637401062497 and parameters: {'n_estimators': 348, 'learning_rate': 0.06334610919763216, 'max_depth': 10, 'scale_pos_weight': 609.7970470653378}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:32:19,782] Trial 190 finished with value: 0.14012581721455136 and parameters: {'n_estimators': 160, 'learning_rate': 0.041172206779554826, 'max_depth': 4, 'scale_pos_weight': 575.3265378661066}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:33:08,389] Trial 191 finished with value: 0.3422675487150526 and parameters: {'n_estimators': 113, 'learning_rate': 0.06698896848713165, 'max_depth': 8, 'scale_pos_weight': 677.8630715800706}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:34:03,563] Trial 192 finished with value: 0.12417565446137695 and parameters: {'n_estimators': 237, 'learning_rate': 0.09212573046720128, 'max_depth': 2, 'scale_pos_weight': 654.4611692190481}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:35:08,878] Trial 193 finished with value: 0.5682271088979426 and parameters: {'n_estimators': 151, 'learning_rate': 0.04972872905603673, 'max_depth': 9, 'scale_pos_weight': 116.73625391325336}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:36:36,293] Trial 194 finished with value: 0.6085999594919753 and parameters: {'n_estimators': 191, 'learning_rate': 0.08222525683930662, 'max_depth': 8, 'scale_pos_weight': 495.9659725874495}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:38:33,377] Trial 195 finished with value: 0.41159313634528927 and parameters: {'n_estimators': 378, 'learning_rate': 0.06427244433475962, 'max_depth': 4, 'scale_pos_weight': 267.8773069850258}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:39:49,949] Trial 196 finished with value: 0.6049978485669788 and parameters: {'n_estimators': 172, 'learning_rate': 0.10084505613336284, 'max_depth': 7, 'scale_pos_weight': 310.45729374153}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:41:08,343] Trial 197 finished with value: 0.27795916727960746 and parameters: {'n_estimators': 285, 'learning_rate': 0.10472833396118153, 'max_depth': 3, 'scale_pos_weight': 453.56943031696744}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:42:16,398] Trial 198 finished with value: 0.12074221054659684 and parameters: {'n_estimators': 302, 'learning_rate': 0.07114542354346479, 'max_depth': 2, 'scale_pos_weight': 674.2796577048849}. Best is trial 60 with value: 0.8854823732036611.\n",
      "[I 2024-03-10 03:46:04,350] Trial 199 finished with value: 0.7789269540596203 and parameters: {'n_estimators': 473, 'learning_rate': 0.0665133183589209, 'max_depth': 8, 'scale_pos_weight': 713.1695222688722}. Best is trial 60 with value: 0.8854823732036611.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value: 0.8854823732036611 (params: {'n_estimators': 477, 'learning_rate': 0.10539285770025873, 'max_depth': 10, 'scale_pos_weight': 286.76251659720305})\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "    study_name=\"Kaggle_Fraud_1\",\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.RandomSampler(seed=42),\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=200)\n",
    "print(f\"Best value: {study.best_value} (params: {study.best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 477,\n",
       " 'learning_rate': 0.10539285770025873,\n",
       " 'max_depth': 10,\n",
       " 'scale_pos_weight': 286.76251659720305}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best choice of provided hyperparameters\n",
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10539285770025873,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=477, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10539285770025873,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=477, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.10539285770025873,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=477, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**params, n_jobs=-1, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_train\n",
      "ROC AUC:   100.00%\n",
      "Precision:  97.05%\n",
      "Recall:    100.00%\n",
      "F1:         98.50%\n",
      "AUPRC:     100.00%\n",
      "\n",
      "Performance metrics: X_test\n",
      "ROC AUC:    99.98%\n",
      "Precision:  85.64%\n",
      "Recall:     92.21%\n",
      "F1:         88.80%\n",
      "AUPRC:      96.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance(X_train, y_train, model_xgb, title='X_train')\n",
    "performance(X_test, y_test, model_xgb, title='X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: X_train\n",
      "ROC AUC:   100.00%\n",
      "Precision:  98.43%\n",
      "Recall:     90.49%\n",
      "F1:         94.29%\n",
      "AUPRC:      98.86%\n",
      "\n",
      "Performance metrics: X_test\n",
      "ROC AUC:    99.99%\n",
      "Precision:  95.94%\n",
      "Recall:     84.84%\n",
      "F1:         90.05%\n",
      "AUPRC:      96.76%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost: default parameters\n",
    "performance(X_train, y_train, model, title='X_train')\n",
    "performance(X_test, y_test, model, title='X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
